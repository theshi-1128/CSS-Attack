

\#\# Page 1

认识图计算和图数据库
什么是图
图（Graph）是⼀种⾮常直观表达事物及其关联关系的数据结构，基本元素是“点”
和“边”，点表示⼀个事物，边就表示他们之间具有⼀定关系
⽐如下⾯这张图，它的点有公司、员⼯、项⽬，边即他们之间的关系⸺公司和员⼯
之间是雇佣关系、员⼯和员⼯之间可以有好友关系、项⽬和员⼯之间也可以有参与
关系。也就是说我们可以⽤图的⽅式来把事物和它们的关系抽象出来。
这是⼀张结构⽐较简单的图。随着点和边不断增加，图数据越来越多越来越复杂，
逐渐形成更丰富的⽹状结构。⽐如⼀些⾦融交易图，它的规模可能会⾮常⼤，超过
10 亿个点，有千亿甚⾄万亿边。可以想象，要真正处理这些图还是很有挑战的。
为什么需要图计算
把计算机想象成⼤脑，我们要解决两个关键问题：数据的存储和分析。
传统的数据存储采⽤关系型数据库，其结构是“表结构”（想象⼀下 Excel 表格）。
⽐如⼀家银⾏的客户转账信息可能包含交易⼈员、交易⾦额、交易时间，记录在⼀
张表格⾥。假如交易⼈ A 和 B 之间有直接转账关系，这种直接关系⽤关系型数据库
是不难发现的。但对于⾮直接关系，关系型数据库就较难“穿透”多个点来发现了，
即便可以处理，查询速度也可能⾮常慢。我们⽤信⽤卡套现来举例。
⾸先是简单的直接套现模式。如左侧图显示，⼀个⼈办了⼀张信⽤卡，他其实不是
真的想去还款，他找了⼀个商店，这个商店提供⼀个⾮法的服务就是信⽤卡套现。
那么他通过信⽤卡付款，把 2020 元钱转到这个商店。这个商店直接就把其中的
2000 元钱返回给付款⼈，就完成了⼀次套现。这样的⼀种套现是⾮常简单的，我们
通过对这个个体，对这个商店的收款记录和付款记录做分析，就可以识别出套现⾏
为。
但右边这张图就复杂了很多。我们可以看到，右上⻆的这个⼈，他还是通过信⽤卡
付款，付了 2020 元钱给了商店。这个时候，商店没有直接把钱退给付款的⼈，⽽
是由⼀个个⼈付了 2000 元钱给到⼀个第三⼈。这个个⼈和商店之间，我们可以通
过⼀些分析发现，他实际上拥有这个商店，所以我们把这种关系叫做同⼈关系。就
是店和⼈虽然看起来是不同的实体，但其实他们之间有⼀个⾮常强的关联。那么他
付款给的第三⼈也不是最开始刷卡的⼈，⽽是刷卡⼈的⼀个亲友，店主付款到了刷
卡⼈亲友的银⾏卡上。那这样的⼀个套现模式就⽐左边的复杂很多了。我们把这种
模式叫做多跳闭环模式。
要分析这种多跳闭环模式，就需要找出复杂的关联关系，⽽不能只对这个个体进⾏
分析。但是⼤家可能会说，你画的这张图很简单呀，我⼀眼就能看出来，这是⼀个
闭环，这个坏⼈我很快就能抓住。
但实际⽣活中情况可能会更加复杂，有更多其它交易和关系，就没那么容易看出来
了。如下图所示，右边这张图可能会有千亿条甚⾄万亿条边，怎么很快地在这个图

\#\# Page 2

上把环找出来，这就对整个分析技术⸺复杂的关联分析技术提出了⾮常⾼的要求，
性能成为了关键。
什么时候要⽤图计算
随着数据量和深度的增加，如果我们⽤传统的关系数据库的⽅法去分析的话，那就
可能⾮常⾮常慢，难以在有效的时间内计算出结果。⽽图计算技术直接将事物与其
关系像制作地图⼀样定位存储下来，直接⽀撑对事物和关系的各种查询和计算⸺这
与我们⼤脑对信息的处理模式很像，⼤脑本身也可以建模成⼀个图。由于提供了对
关联数据最直接的表达，以及图模型对异构数据天然的包容⼒，可以很好的解决⽬
前遇到的关联数据分析问题。
由此可⻅，关系型数据库的设计擅⻓回答“已知”的问题，⽽图数据库可以回答超出
设想的“未知”问题。相较于关系型数据库，图数据库是真正注重“关系”的数据库。
我们刚才举的是⾦融⽅⾯的例⼦，但是图计算的⽤途远远不限于⾦融⾏业。在互联
⽹、⼯业领域、医药、公共卫⽣、公共安全等领域都有很多的应⽤。如绘制⽤户社
交关系图谱进⾏社交影响⼒排名、好友推荐；构建设备关系⽹络图谱实现物联⽹建
模分析、供电⽹络建模分析等。
随着互联⽹和 5G 时代数据指数级增⻓，数据之间的关系越来越复杂，企业管理和
分析数据⾯临更⾼难度。越来越多的企业管理者们开始关注以图为代表的技术来更
智能地使⽤数据，Google、Facebook 等科技巨头也早就在通过图数据库的⼒量来
⽀撑主要业务应⽤。
国际知名咨询公司 Gartner，每年都会发布各种技术趋势的报告。在 2021 年的《⼗
⼤数据分析技术趋势》报告中，Gartner 提到了“Graph relates everything”。这是
⼀个⾮常有趣的双关，即图连接万物，⼀⽅⾯表示了图的本质，就是把各种事物连
起来，另⼀⽅⾯也表达了图会在数据分析的各个领域得到⼴泛应⽤。Gartner 预测到
2025 年，图技术在数据和分析创新中的占⽐将从 2021 年的 10%上升到 80%。
蚂蚁集团开源图数据库 TuGraph，成⽴图计算开源委员会
9 ⽉ 1 ⽇，2022 世界⼈⼯智能⼤会“新⼀代图智能技术发展与实践论坛”上，蚂蚁集
团图计算负责⼈陈⽂光宣布开源蚂蚁集团⾼性能图数据库 TuGraph 单机版，并成⽴
图计算开源技术委员会，中国⼯程院院⼠郑纬⺠、陈纯分别担任主席、副主席，5
位业界知名专家担任委员。
TuGraph 由蚂蚁集团和清华⼤学共同研发，是图数据库权威测试世界纪录保持者，
也是世界上有测试纪录的“最快”的图数据库。
随着 TuGraph 的开源，图数据领域将迎来⼀款性能卓越、功能丰富、⽣态完备的开

\#\# Page 3

源产品。
开发者可以聚焦应⽤层，轻松打造属于⾃⼰的图数据，从⽽提升⾏业整体技术应⽤
⽔位。TuGraph 开源采⽤ Apache2\.0 协议，在 Github 和 Gitee 上进⾏托管。
图数据库区别于关系型数据库，基于图模型，使⽤点边来表示、存储、处理数据，
拥有灵活的数据抽象模型，能够更好地表达出“关系”的概念。
蚂蚁 TuGraph 是⼀套分布式图数据库系统，可以⽀持万亿级边上的实时查询。此次
开源的 TuGraph 单机版，同样具备完备的图数据库基础功能和成熟的产品设计，可
以轻松⽀持 TB 级别数据和百亿级别⼤图，⾜以满⾜⼤多数业务场景需求。相较于
市场上常⻅的开源产品，TuGraph 单机版的性能⾼ 10 倍以上。
蚂蚁集团 2015 年开始⾃主研发分布式图数据库、流式图计算等图相关技术，2016
年发布⾃研分布式图数据库，并应⽤于⽀付宝。⾄今 TuGraph 已应⽤于蚂蚁内部
150 多个场景，包括在线⽀付的实时链路，以⽀付宝⻛险识别能⼒提升近 10 倍、⻛
险审理分析效率提升 90%的成绩，验证了其⾼可靠性。
就在上个⽉，LDBC（关联数据基准委员会）发布最新图数据库 SNB 测试结果，
TuGraph 在功能完整性、吞吐率、响应速度等层⾯全球领先。
⽬前，蚂蚁集团已形成了⼀套以图数据库为底座、同时包含流式图计算，离线图学
习的⼤规模图计算系统。
蚂蚁集团图数据库负责⼈洪春涛表示，图技术是未来⼤数据、⼈⼯智能和⾼性能计
算产业发展的关键所在，它很有可能会成为下⼀代的数据底座。蚂蚁集团愿意通过
开源持续输出核⼼技术优势，推动图数据库更⼴泛的应⽤⽣态，携⼿⾏业抢占技术
⾼地，不断探索技术的可能性。
技术解读 \| TuGraph 图分析引擎技术剖析
图分析引擎⼜称图计算框架，主要⽤来进⾏复杂图分析，是⼀种能够全量数据集运
⾏快速循环迭代的技术，适⽤场景包括社区发现、基因序列预测、重要性排名等，
典型算法有 PageRank、WCC、BFS、LPA、SSSP。
TuGraph 图数据管理平台社区版已于 2022 年 9 ⽉在 Github 开源，本⽂将对
TuGraph 图分析引擎的技术进⾏剖析。
1 TuGraph 图分析引擎概览
TuGraph 的图分析引擎，⾯向的场景主要是全图/全量数据分析类的任务。借助
TuGraph 的 C\+\+ 图分析引擎 API ，⽤户可以对不同数据来源的图数据快速导出⼀
个待处理的复杂⼦图，然后在该⼦图上运⾏诸如 BFS、PageRank、LPA、WCC 等
迭代式图算法，最后根据运⾏结果做出相应的对策。 在 TuGraph 中，导出和计算

\#\# Page 4

过程均可以通过在内存中并⾏处理的⽅式进⾏加速，从⽽达到近乎实时的处理分
析，和传统⽅法相⽐，即避免了数据导出落盘的开销，⼜能使⽤紧凑的图数据结构
获得计算的理想性能。
根据数据来源及实现不同，可分为 Procedure、Embed 和 Standalone 三种运⾏模
式。其中 Procedure 模式和 Embed 模式的数据源是图存储中加载图数据，分别适
⽤于 Client/Server 部署，以及服务端直接调⽤，后者多⽤于调试。
Standalone 模式的数据源是 TXT、⼆进制、ODPS ⽂件等外部数据源，能够独⽴于
图数据存储直接运⾏分析算法。
TuGraph 图计算系统社区版内置 6 个基础算法，商业版内置了共 34 种算法。涵盖
了图结构、社区发现、路径查询、重要性分析、模式挖掘和关联性分析的六⼤类常
⽤⽅法，可以满⾜多种业务场景需要，因此⽤户⼏乎不需要⾃⼰实现具体的图计算
过程。
算法类型 中⽂算法名 英⽂算法名 程序名
Breadth\-First
⼴度优先搜索 bfs
Search
Single\-Source
单源最短路径 sssp
Shortest Path
All\-Pair
全对最短路径 apsp
路径查询 Shortest Path
Multiple\-
多源最短路径 source mssp
Shortest Paths
两点间最短路 Single\-Pair
spsp
径 Shortest Path
⽹⻚排序 Pagerank pagerank
Betweenness
介数中⼼度 bc
Centrality
Belief
置信度传播 bp
Propagation
Closeness
距离中⼼度 clce
Centrality
个性化⽹⻚排 Personalized
ppr
重要性分析 序 PageRank
Weighted
带权重的⽹⻚
Pagerank wpagerank
排序
Algorithm
信任指数排名 Trustrank trustrank
sybil检测算法 Sybil Rank sybilrank
Hyperlink\-
超链接主题搜
Induced Topic hits
索
Search
Local
平均集聚系数 Clustering lcc
Coefficient
Common
共同邻居 cn
关联性分析 Neighborhood
Degree
度数关联度 dc
Correlation
杰卡德系数 Jaccard Index ji
Dimension
直径估计 de
Estimation
K核算法 K\-core kcore
k阶团计数算
Kcliques kcliques
法
图结构
k阶桁架计数
Ktruss ktruss
算法
Maximal
最⼤独⽴集算
independent mis
法
set
Weakly
弱连通分量 Connected wcc
Components
Label
标签传播 Propagation lpa
Algorithm
EgoNet算法 EgoNet en
鲁汶社区发现 Louvain louvain
Strongly
社区发现 强连通分量 Connected scc
Components
Speaker\-
listener Label
监听标签传播 slpa
Propagation
Algorithm
莱顿算法 Leiden leiden
Weighted
带权重的标签 Label
wlpa
传播 Propagation
Algorithm
Triangle
三⻆计数 triangle
Counting
模式挖掘 Subgraph subgraph\_isom
⼦图匹配算法
Isomorphism orphism
模式匹配算法 Motif motif

\#\# Page 5

算法类型 中⽂算法名 英⽂算法名 程序名
Breadth\-First
⼴度优先搜索 bfs
Search
Single\-Source
单源最短路径 sssp
Shortest Path
All\-Pair
全对最短路径 apsp
路径查询 Shortest Path
Multiple\-
多源最短路径 source mssp
Shortest Paths
两点间最短路 Single\-Pair
spsp
径 Shortest Path
⽹⻚排序 Pagerank pagerank
Betweenness
介数中⼼度 bc
Centrality
Belief
置信度传播 bp
Propagation
Closeness
距离中⼼度 clce
Centrality
个性化⽹⻚排 Personalized
ppr
重要性分析 序 PageRank
Weighted
带权重的⽹⻚
Pagerank wpagerank
排序
Algorithm
信任指数排名 Trustrank trustrank
sybil检测算法 Sybil Rank sybilrank
Hyperlink\-
超链接主题搜
Induced Topic hits
索
Search
Local
平均集聚系数 Clustering lcc
Coefficient
Common
共同邻居 cn
关联性分析 Neighborhood
Degree
度数关联度 dc
Correlation
杰卡德系数 Jaccard Index ji
Dimension
直径估计 de
Estimation
K核算法 K\-core kcore
k阶团计数算
Kcliques kcliques
法
图结构
k阶桁架计数
Ktruss ktruss
算法
Maximal
最⼤独⽴集算
independent mis
法
set
Weakly
弱连通分量 Connected wcc
Components
Label
标签传播 Propagation lpa
Algorithm
EgoNet算法 EgoNet en
鲁汶社区发现 Louvain louvain
Strongly
社区发现 强连通分量 Connected scc
Components
Speaker\-
listener Label
监听标签传播 slpa
Propagation
Algorithm
莱顿算法 Leiden leiden
Weighted
带权重的标签 Label
wlpa
传播 Propagation
Algorithm
Triangle
三⻆计数 triangle
Counting
模式挖掘 Subgraph subgraph\_isom
⼦图匹配算法
Isomorphism orphism
模式匹配算法 Motif motif

\#\# Page 6

算法类型 中⽂算法名 英⽂算法名 程序名
Breadth\-First
⼴度优先搜索 bfs
Search
Single\-Source
单源最短路径 sssp
Shortest Path
All\-Pair
全对最短路径 apsp
路径查询 Shortest Path
Multiple\-
多源最短路径 source mssp
Shortest Paths
两点间最短路 Single\-Pair
spsp
径 Shortest Path
⽹⻚排序 Pagerank pagerank
Betweenness
介数中⼼度 bc
Centrality
Belief
置信度传播 bp
Propagation
Closeness
距离中⼼度 clce
Centrality
个性化⽹⻚排 Personalized
ppr
重要性分析 序 PageRank
Weighted
带权重的⽹⻚
Pagerank wpagerank
排序
Algorithm
信任指数排名 Trustrank trustrank
sybil检测算法 Sybil Rank sybilrank
Hyperlink\-
超链接主题搜
Induced Topic hits
索
Search
Local
平均集聚系数 Clustering lcc
Coefficient
Common
共同邻居 cn
关联性分析 Neighborhood
Degree
度数关联度 dc
Correlation
杰卡德系数 Jaccard Index ji
Dimension
直径估计 de
Estimation
K核算法 K\-core kcore
k阶团计数算
Kcliques kcliques
法
图结构
k阶桁架计数
Ktruss ktruss
算法
Maximal
最⼤独⽴集算
independent mis
法
set
Weakly
弱连通分量 Connected wcc
Components
Label
标签传播 Propagation lpa
Algorithm
EgoNet算法 EgoNet en
鲁汶社区发现 Louvain louvain
Strongly
社区发现 强连通分量 Connected scc
Components
Speaker\-
listener Label
监听标签传播 slpa
Propagation
Algorithm
莱顿算法 Leiden leiden
Weighted
带权重的标签 Label
wlpa
传播 Propagation
Algorithm
Triangle
三⻆计数 triangle
Counting
模式挖掘 Subgraph subgraph\_isom
⼦图匹配算法
Isomorphism orphism
模式匹配算法 Motif motif
表1\.1 TuGraph内置算法
2 功能介绍
2\.1 图分析框架 图分析框架作为图分析引擎的“⻣架”，可以联合多种模块有效的耦
合协同⼯作。⼀般分为预处理、算法过程、结果分析三个阶段。
预处理部分⽤于读⼊数据及参数进⾏图构建及相关信息的存储统计，并整理出算法
过程所需的参数及数据。
算法过程会根据得到的数据通过特定的算法进⾏逻辑计算，并得到结果数据。 结果
分析部分根据得到的结果数据进⾏个性化处理（如取最值等），并将重要的信息写
回和打印输出操作。
2\.2 点边筛选器 点边筛选器作⽤于图分析引擎中的 Procedure 和 Embed 模式。对
于图存储数据源可根据⽤户需要和实际业务场景对图数据进⾏筛查，选择有效的点

\#\# Page 7

边进⾏图结构的构建。 2\.3 ⼀致性快照 TuGraph 中的 Procedure 和 Embed 模式能
够提供数据“快照”，即建⽴⼀个对指定数据集的完全可⽤拷⻉，该拷⻉包括相应数
据在某个时间点（拷⻉开始的时间点）的镜像。由于 OLAP 的操作仅涉及读操作⽽
不涉及写操作，OlapOnDB 会以⼀种更紧凑的⽅式对数据进⾏排布，在节省空间的
同时，提⾼数据访问的局部性。 2\.4 块状读写模块 块状读写模块作⽤于图分析引擎
中的 Standalone 模式，⽤于对不同外部数据源的数据进⾏⾼效读⼊，同时也包含对
内部算法处理后的图数据结果写回。 2\.5 参数模块 参数模块作⽤于分析引擎中的
Standalone 模式，⽤于对图的⼀般信息（如数据来源，算法名称，数据输⼊、输出
路径，顶点个数等）以及根据不同数据来源、不同算法所配置的不同信息参数进⾏
接受和整理，传输给图算法及各个模块，同时将最终结果模块化展示。
3 使⽤示例
由前⽂所述可知，图分析引擎分为 Standalone、Embed 和 Procedure 模式，现在
以 bfs 算法为例分别介绍他们的使⽤⽅式。 3\.1 Procedure 模式 Procedure 模式主
要⽤于 Client/Sever 的 TuGraph 运⾏时，图算法的加载和调⽤。 在 TuGraph/
plugins ⽬录下执⾏ bash make\_so.sh bfs 即可在 TuGraph/plugins ⽬录下的
到 bfs.so ⽂件，将该⽂件以插件形式上传⾄ TuGraph\-web，输⼊参数后即可执
⾏。 示例： 在 TuGraph/plugins 编译.so 算法⽂件
bash make\_so.sh bfs
将 bfs.so ⽂件以插件形式加载⾄ TuGraph\-web 后，输⼊如下 json 参数：
即可得到返回结果。
输出内容解释： num\_edges: 表示该图数据的边数量 num\_vertices: 表示该图数据
顶点的数量 prepare\_cost: 表示预处理阶段所需要的时间。预处理阶段的⼯作：加
载参数、图数据加载、索引初始化等。 core\_cost: 表示算法运⾏所需要的时间。
found\_vertices: 表示查找到顶点的个数。 output\_cost: 表示算法结果写回 db 所需
要的时间。 total\_cost: 表示执⾏该算法整体运⾏时间。 3\.2 Embed 模式 该种⽅式
主要⽤于 TuGraph 在后台程序中对预加载的图存储数据进⾏算法分析，多⽤于快速
调试。在 TuGraph/plugins ⽬录下对 embed\_main.cpp ⽂件完善，补充数据名称、
输⼊参数、数据路径等信息，示例如下：
保存后在 TuGraph/plugins ⽬录下执⾏ bash make\_so.sh bfs 即可在 TuGraph/
plugins/cpp ⽬录下的到 bfs\_procedure ⽂件，bash make\_embed.sh bfs
在 TuGraph/plugins ⽂件夹下执⾏./cpp/bfs\_procedure 即可得到返回结果。
3\.3 Standalone 模式 Standalone 模式可以独⽴于图存储运⾏，直接从⽂本⽂件或
ODPS 读取 Edgelist 形式的图数据。在 TuGraph/build ⽬录下执⾏ make
bfs\_standalone 即可得到 bfs\_standalone ⽂件,该⽂件⽣成与 TuGraph/build/
output/algo ⽂件夹下。运⾏：在 TuGraph/build ⽬录下执⾏./output/algo/

\#\# Page 8

bfs\_standalone \-–type \[type] –\-input\_dir \[input\_dir] \-–vertices \[vertices] \-\-root
\[root] –\-output\_dir \[output\_dir]
• \[type]：表示输⼊图⽂件的类型来源，包含 text ⽂本⽂件、BINARY\_FILE ⼆
进制⽂件和 ODPS 源。
• \[input\_dir]：表示输⼊图⽂件的⽂件夹路径，⽂件夹下可包含⼀个或多个输⼊
⽂件。TuGraph 在读取输⼊⽂件时会读取\[input\_dir]下的所有⽂件，要求
\[input\_dir]下只能包含输⼊⽂件，不能包含其它⽂件。参数不可省略。
• \[vertices]：表示图的顶点个数，为 0 时表示⽤户希望系统⾃动识别顶点数
量；为⾮零值时表示⽤户希望⾃定义顶点个数，要求⽤户⾃定义顶点个数需
⼤于最⼤的顶点 ID。参数可省略，默认值为 0。
• \[root]：表示进⾏ bfs 的起始顶点 id。参数不可省略。
• \[output\_dir]：表示输出数据保存的⽂件夹路径，将输出内容保存⾄该⽂件
中，参数不可省略。
示例：在 TuGraph/build 编译 standalone 算法程序
在 TuGraph/build/output ⽬录下运⾏ text 源⽂件
得到运⾏结果：
结果参数解释同上。
4 ⼩结
综上，图分析引擎可以⾼效、快速的处理多种来源的数据，其并⾏的图构建⽅式保
证了内存占⽤⼩的特点。此外，图分析引擎也具有易于安装部署、灵活性⾼、耦合
程度低、易于上⼿等对⽤户友好特性，可以帮助⽤户结合具体业务解决问题。
TuGraph开源JAVA客户端⼯具TuGraph\-OGM，⽆缝对接JAVA开发⽣态
TuGraph 图数据库提供了 JAVA、C\+\+、Python 等多种语⾔的 SDK ⽀持，⽅便客
户在各种场景下使⽤。⽤户使⽤ SDK 向TuGraph服务器发送Cypher请求，服务器
则以 JSON形式返回数据。近⽇，TuGraph 推出了⼀款⾯向 JAVA 客户端⽤户的开
发⼯具 TuGraph\-OGM (Object Graph Mapping)，为⽤户提供了对象操作接⼝，相
较 Cypher/JSON 接⼝应⽤起来更加便捷。
OGM 类似于关系数据库中的 ORM（Object Relational Model），可以将数据库返
回的数据⾃动映射成 JAVA 中的对象，⽅便⽤户读取，⽽⽤户对这些对象的更新操
作也可以被⾃动翻译成 Cypher 语句发送给服务器。这样即便是完全不懂 Cypher 的
⽤户，也可以通过操作对象与数据库进⾏交互，⼤⼤降低了图数据库的使⽤⻔槛。

\#\# Page 9

TuGraph\-OGM 同时也兼容其他开源产品 OGM ⼯具如 Neo4j\-OGM，⽅便⽤户将⼯
程在不同数据库与 TuGraph数据库间⽆缝迁移。本⽂将对 TuGraph\-OGM 进⾏全⾯
的介绍。
0 映射原理
TuGraph\-OGM 将 JAVA 对象映射为图的对象，类映射为点，类的属性映射为图中
的属性，类中的⽅法映射为操作 TuGraph 的查询语句。
以电影场景为例，对演员、电影、导演之间的关系进⾏数据化，就形成了⾮常典型
的图数据。举⼀个简单的示例，演员Alice在1990年和2019年分别出演了两部电影
《Jokes》和《Speed》，其中《Jokes》的导演是Frank Darabont。
以图的思维来看，演员、导演、电影可以被映射为三种不同的节点，⽽出演、执导
可以被映射为两种边，映射结果如上图所示，将数据存⼊图数据库后，相关的开发
⼈员就可以使⽤各类图查询语⾔对数据进⾏查询。
但对⾮图数据库相关的开发⼈员来说，这个例⼦中的演员、导演、电影作为实体，
同样可以映射为类中的对象，⽽与实体相关联的对象可以通过集合存储，这是⼤多
数开发⼈员熟悉的领域。
1 TuGraph\-OGM架构
TuGraph\-OGM可被看做⼀个"翻译器"，主要功能是将开发⼈员对JAVA对象的⼀些
操作翻译为TuGraph可理解的图查询语⾔Cypher请求，并将该操作返回的结果，再
次翻译为JAVA对象。架构图如下所示：
3 使⽤示例
详细示例请参考tugraph\-ogm\-integration\-tests 在pom.xml中引⼊依赖
3\.1 构建图对象
⾸先需要通过注解标明图中的实体。
@NodeEntity：该注解标明的类为节点类。
@Relationship：⽤于标明边，同时@Relationship中可指定label与边的指向。
@Id：⽤于标明identity，是OGM中数据的唯⼀标识。
3\.2 与TuGraph建⽴连接
当前TuGraph\-OGM提供了RPC driver⽤于连接TuGraph，具体配置如下所示：

\#\# Page 10

3\.3 通过OGM进⾏增删改查
OGM⽀持对TuGraph的实体执⾏CRUD 操作，同时⽀持发送任意TuGraph⽀持的
Cypher语句，包括通过CALL调⽤存储过程。
CREATE
在完成图对象的构建后，即可通过类的实例化创建节点，当两个节点互相存储在对
⽅的集合（该集合在构建时被标注为边）中，就形成了⼀条边，最后使⽤
session.save⽅法将数据存⼊数据库。
注意：TuGraph数据库为强schema类型数据库，在创建实体前需要该数据的label已
经存在，且新建过程中需要提供唯⼀的主键。
DELETE
使⽤session.delete⽅法删除节点，同时会删除与节点相关联的所有边。
UPDATE
修改已创建的节点的属性，再次调⽤session.save⽅法会对节点进⾏更新。
MATCH
session.load⽅法⽤于根据节点id查找节点。 session.loadALL⽅法⽤于批量查找节
点，⽀持通过多个节点id查找节点、查找某⼀类型的所有节点、带有filter的查询。
filter查询需要新建Filter，传⼊参数ComparisonOperatorx0;可选为：
EQUALSx0;、GREATER\_THANx0;、LESS\_THAN
QUERY WITH CYPHER
OGM⽀持通过queryForObject、query⽅法向TuGraph发送Cypher查询，由于
Cypher查询的灵活性，需要⽤户⾃⾏指定返回结果格式。
session.queryForObject⽅法：需要在⽅法第⼀个参数处指定返回类型，可设定为
某⼀实体类或数字类型。
session.query⽅法：Cypher查询的返回结果被存储为Result类型，其内部数据需要
⽤户⾃⾏解析，以下⽅代码为例，传⼊数据库的Cypher为CREATE查询，返回结果
createResult可被解析为QueryStatistics，可获取到此次查询被创建的节点与边的
数⽬。
关于TuGraph

\#\# Page 11

⾼性能图数据库 TuGraph（https://github.com/TuGraph\-family/tugraph\-db） 由
蚂蚁集团和清华⼤学共同研发，经国际图数据库基准性能权威测试，是 LDBC\-SNB
世界纪录保持者，在功能完整性、吞吐率、响应时间等技术指标均达到全球领先⽔
平，为⽤户管理和分析复杂关联数据提供了⾼效易⽤可靠的平台。
历经蚂蚁万亿级业务的实际场景锤炼，TuGraph 已应⽤于蚂蚁内部150多个场景，
助⼒⽀付宝2021年资产损失率⼩于亿分之0\.98。关联数据爆炸性增⻓对图计算⾼效
处理提出迫切需求，TuGraph 已被成熟应⽤于⾦融⻛控、设备管理等内外部应⽤，
适⽤于⾦融、⼯业、互联⽹、社交、电信、政务等领域的关系数据管理和分析挖
掘。
2022年9⽉，TuGraph 单机版开源，提供了完备的图数据库基础功能和成熟的产品
设计，拥有完整的事务⽀持和丰富的系统特性，单机可部署，使⽤成本低，⽀持TB
级别的数据规模。
蚂蚁⾼性能图数据库 TuGraph\-DB 的技术思考与实践
在近⽇举⾏的 DTCC 2022 第⼗三届中国数据库技术⼤会\-图数据技术与应⽤创新
专场，蚂蚁集团图数据库负责⼈洪春涛博⼠分享了蚂蚁⾼性能图数据库 TuGraph\-
DB 的技术思考和实践，以下为演讲内容要点回顾。
图计算的优势
图计算是⼀种⾼效的抽象计算⽅法，可以⽅便地处理复杂的多维数据。我们将员⼯
和公司之间的关系画成图，这样可以快速查询员⼯的信息，例如员⼯的⼯作情况、
与其他员⼯的关系以及与哪些公司有联系。相⽐之下，在关系数据库中，我们需要
分别建⽴员⼯信息表、公司信息表以及员⼯和公司之间的关系表。这就把整个数据
切成了很多张⼆维表，在实际应⽤系统中经常能够看到⼏百上千张表。这样会使得
系统变得更加复杂，需要基于多张表去做推断，对⼈或机器来说都会带来挑战。
对⽐来看什么是简单查询和复杂查询：
图中表格的前两⾏属于⽐较简单的查询，⽐如某个员⼯的⼯龄，直接找到对应的那
⼀⾏然后取出来就可以；⽐如找出所有的雇员数⼤于 5 的公司，可能在雇佣关系表
中就能找出来，在关系数据库⾥这些都属于常规的操作。
但如果查询再复杂⼀点，我想知道员⼯ A 和员⼯ C 之间有什么关系，不⼀定是⼀跳
的关系，可能包含在同⼀家公司⼯作，也可能包含参与了同⼀个项⽬，甚⾄还包含
他们有⼀个共同好友，这些关系就是多种多样的，想⽤ SQL 列举所有可能的关系其
实就没有那么容易了。如果确定知道这⾥可能有⼏种关系，还能靠 SQL 穷举出来，
但随着表越来越多，⾥⾯的关系可能有⼏百上千的时候，再想去穷举就⾮常难了。
最后还有⼀种更复杂的查询，⽐如想找员⼯ A 和员⼯ E 的所有关系，可能包括 A 认
识 B，B 认识 C，C 认识 E，相当于在做⼀个不定⻓跳数的查询，在 SQL ⾥⾯就⾮
常难写了，相信绝⼤多数⼈都难以写出这种查询。
业界有句话，所谓的关系数据库实际上并不擅⻓处理关系。例如，员⼯ A 和 E 之间
的所有关系实际上就是我们要查询的关系，但在关系数据库中处理这种关系查询实

\#\# Page 12

际上是不够友好的。这是图数据库的优势所在，它们更擅⻓处理复杂的关系数据。
我们发现，⼤部分浅显的数据信息都可以⽐较容易地挖掘出来，但要想更深⼊地利
⽤数据产⽣更多的价值，就必须挖掘更深层次的信息，这时就⼀定会遇到这些复杂
的关系，这也是为什么图数据库越来越受欢迎的原因。
为什么图数据库开始流⾏
图数据库的概念最早出现在七⼋⼗年代初期，但当时为什么⼈们没有选择使⽤图数
据库，⽽是选择了关系数据库呢？我认为主要原因是，当时的计算机并不那么强
⼤，使⽤⼆维表格形式的关系数据库对计算机来说更友好。我们知道，计算机最擅
⻓的事情就是重复的劳动，重复的任务。如果我们要在⼀张⼆维表中找⼀⾏数据，
我们可以⼀⾏⼀⾏查找，或者使⽤⼆分查找（如果数据是树状有序的）。每⼀层都
是重复的算法在运⾏，这对计算机来说是⼀个⾮常规整的数据，容易处理。但如果
把数据抽象成⼀张图，那么难度就会⼤很多，对计算机来说会更难处理。
举个例⼦，⼀个员⼯可能与其他⼈有各种不同的关系，⽐如朋友关系、雇佣关系、
参与项⽬关系，每种关系的类型都不同，对应的数据也都不同。此外，⼀个点上的
边数也⾮常不规律，有的⼈可能只有⼏个好友，⽽在微博上，⼀个普通⼈可能有两
三百个粉丝，⽽⼤ V 账号可能有数百万甚⾄上亿的粉丝。这样⼀来，存储数据时，
普通⼈和⼤ V 之间的差距就⾮常⼤了，对计算机来说，处理这两种数据的差异也会
很⼤。
我们知道，在七⼋⼗年代，计算机相对来说很弱，如果那个时候使⽤图来表示数
据，整个处理和查询的难度就会⼤很多。所以，⼈们选择使⽤关系数据表的形式表
示数据。事实上，那个时候有⼈做过图数据库，但并没有流⾏起来，原因就是性能
相对关系数据库来说差得太多了。
我们知道，所有的事物，尤其是电脑，⼀直在不断进步。这包括硬件和软件⽅⾯的
改进。如今的硬件和⼏⼗年前的硬件完全不是⼀个概念，⽽现在的软件优化也⼤不
相同。随着这些改进，我们会发现对当前的电脑和计算机系统来说，使⽤图数据库
带来的额外开销可能不是很⼤的问题。
举个例⼦，我们会发现，过去⼈们都使⽤低级编程语⾔编写程序，但随着时间的推
移，有了⾼级语⾔。⽐如最开始、最原始的电脑可能是⽤纸袋和机器码写程序，后
来有了汇编，再后来有 C 语⾔、C\+\+，现在很多⼈都直接写 Python。虽然 Python
程序的执⾏速度可能较慢，但是写的很快，⽽⽤⽤ C\+\+或者汇编去写得写半天，对
于编写程序到最终得出结果的整个过程来说，使⽤ Python 会更⽅便。
计算机编程语⾔的发展是从低级向⾼级演变的，数据抽象也是⼀样。我们认为，未
来的数据抽象⼀定会对⼈更友好⼀些，⽽不是专注于对机器更友好。如图所示，编
程语⾔的发展是从低级语⾔向⾼级语⾔转变的，我们也认为数据抽象层次也会慢慢
从低层次表格抽象向⾼层次图表抽象发展。
图计算在蚂蚁的应⽤
⾃ 2015 年开始，蚂蚁实际上投⼊了⼤量资源来研究图计算，研究如何在蚂蚁的业
务中使⽤图计算。例如数据⾎缘应⽤。在对业务的处理过程中，我们需要较好地追

\#\# Page 13

踪这些数据的流转路径，如果修改了⼀份源数据会对下游数据产⽣什么影响，会对
最终业务产⽣什么影响。为了更好地追踪，我们使⽤图数据库来存储数据。
另⼀个⽐较有趣的应⽤场景就是程序分析。相信⼏乎所有互联⽹公司内部都有⼤量
的程序，因此，我们需要管理这些程序，并在每次提交代码时了解将会对哪些内容
产⽣影响。为此，蚂蚁负责程序分析的团队会分析这⾥的图数据。例如，定义⼀个
变量 A，然后使⽤变量 A，“定义”与“使⽤”之间就会有⼀条边，使⽤关系会存储在
图数据库中。⽬前我们的图中已经有超过 200 亿条边，这是⼀个⾮常⼤的数据量。
我们需要对这些数据进⾏存储、查询和分析，这是蚂蚁公司内部⾮常多的图数据场
景之⼀。
举个例⼦来说明优惠券反套现的场景：满额返券是⼀种⽐较常⻅的促销⽅式，⽐如
购物满 2000 元就可以享受 100 元的优惠。这种情况下，如果正常消费，⽤户花费
2000 元，通过返券省下 100 元。但是有些⼈会想办法注册假商铺，进⾏虚假交
易，⽬的是把平台补贴的优惠券套出来。因此当⽤户去买东⻄，平台要去付补贴的
过程，我们需要去实时检测⼀下会不会有可疑的资⾦交易情况。
蚂蚁有很多业务需要研究图计算系统和图数据库等技术来满⾜需求，因为这些业务
需要对⼤量的点边进⾏分析，数据量超过了 100TB，基本上已经达到了 PB 级别。
我们需要对这些图进⾏实时查询，吞吐率⼤约在百万级别。由于需要对⽤户的付款
进⾏实时判断，所以需要⽐较低的延迟，⼤约在 20 毫秒的级别。如果延迟太⻓，会
导致⽤户体验很差，⽐如付款需要等待 5 秒才能完成，这样就会⾮常麻烦。
图计算系统建设中的问题与挑战
在建⽴蚂蚁图计算系统的过程中，我们遇到了各种各样的问题。为了解决这些问
题，我们与学术界和许多研究界的同事⼀起合作，并发表了许多相关的学术论⽂，
包括 EuroSys 等。然⽽，我们在建⽴系统的过程中发现，⽬前的图计算仍处于较早
期的阶段，因此许多标准尚未成形。这对我们来说是⼀个棘⼿的问题。例如，在关
系型数据库中，查询语⾔基本上就是 SQL，但在图数据库中，仅查询语⾔就有许多
种，包括 Gremlin、G\-SQL 等等。这导致了市场的碎⽚化，⼈们学习和使⽤的成本
也很⾼。
在建⽴图计算系统的过程中，我们也遇到了许多挑战。为了分担较⼤的通信量，需
要将图数据分布到多台机器上，但这会导致边的信息在不同机器之间传递，造成⼤
量的通信。此外，单次查询所涉及的数据量也⽐较⼤，例如五跳查询涉及的点数就
已达到 10 的五次⽅，图中还存在⼀些⾮常⼤的点。同时，⽤户对图计算系统的需求
也⼗分多样，既有快速查询的需求，也有对复杂算法（如社区发现）的需求，单⼀
系统很难满⾜这些不同的需求。
TuGraph 技术优势
蚂蚁⾃⼰开发了⼀套图计算系统 TuGraph，既能解决图数据的存储问题，也能解决
流式计算、离线计算和图学习的问题。⽬前，超过 100 个业务线和 300 多个场景都
在使⽤这套系统。这套系统在 2021 年获得了世界互联⽹⼤会领先科技成果奖。
在 TuGraph 中，性能是⼀个重要的因素，因为图数据集的体积很⼤，如果性能不佳

\#\# Page 14

就会浪费机器资源，导致许多情况下⽆法完成任务。⽐如，希望业务的查询能在⼏
⼗毫秒内返回结果，但是如果做的性能不好，⼏秒钟才能返回结果，就⽆法作为在
线查询使⽤。因此，我们是⾮常对性能是很重视的，其中在 LDBC\-SNB 标准测试中
（类似于数据库领域性能标准测试 TPC\-C），TuGraph 仍然是世界纪录的保持者。
TuGraph 的整个图存储是建⽴在完美哈希的基础上的，这是我们与其他图系统的⼀
个重要区别。⽬前，⼤多数图系统使⽤的是基于数的存储，但数的问题在于永远存
在⼀个 LogN 的查找操作。然⽽，在图中可以看到，不同的顶点之间实际上是⽆序
的，不需要有顺序，所以顶点这个级别实际上是基于哈希的，理论上，顶点的读取
是最优的。
此外，TuGraph 还参与了许多标准的定制，整个系统在尽量往标准化的⽅向去做。
除了为内部提供服务，我们还向外提供服务，主要是因为，作为⼀个系统，如果只
为有限的客户提供服务，就很容易构建成⼀个专有系统。我们希望这是⼀个标准
化、开放的系统，所以我们也在对外提供图计算系统的产品和服务。⽬前，我们也
有很多外部客户，包括⾦融、⼯业、互联⽹以及政企领域。
开源开放，共建发展
整个图计算系统⽬前仍处于较早期的阶段，我们认为还有很多⼯作要做，包括提升
应⽤性、性能和降低成本。所有的系统都会有这些问题。但是，如果希望普及，我
们认为最重要的是有健康的⽣态，来推动图计算系统的发展，需要有更多的⽤户和
更多的场景使⽤这个系统。
所有的计算机系统都需要去有⼀个更开放、更⼤的⽣态才能促进发展。蚂蚁有⼀句
话叫做“成熟⼀个、开放⼀个”，⼀个系统成熟以后，我们就会试着开放出去，让更
多的⼈去⽤。今年 9 ⽉，我们已经在 GitHub 上开源了 TuGraph 中的单机版图数据
库，以及⼀个离线图分析引擎 TuGraph Compute。分布式图数据库和流式图计算现
在已经包含在我们的商业化版本中，包括⼀站式图研发平台。我们计划在未来迭代
更多更丰富的系统功能，希望能做得更好。
TuGraph 开源版特⾊
为什么要去开源单机版⽽不是分布式版本？主要是考虑到它的部署和使⽤成本⽐分
布式版本要低得多，同时功能也很完整、独⽴。我们希望这样可以让许多刚开始使
⽤图数据库或有使⽤图数据库解决问题的想法的⼈，可以先尝试⽤我们的单机版图
数据库。因为它的部署⾮常简单，如果跑起来没有问题，那么再考虑是否需要分布
式版本。如果确实需要，我们可以再跟进这个问题。
我们的单机版图数据库已经能够⽀持 TB 级别的数据，我们内部也有很多情况使⽤
单机版图数据库。在单台机器上，我们最⼤的数据量也达到了 2TB 多，在线上运
⾏，能够处理百亿级别的点边。事实上，⼤多数⽤户使⽤单机版图数据库都是⾜够
的。由于单机版的图数据库很容易优化，我们对它进⾏了极致的优化，因此单机版
图数据库在性能上可以满⾜绝⼤多数场景的需求。此外，它的系统特性也很全⾯，
包括⾼可⽤性、多图⽀持、权限管理、⽇志记录等，它可以被看作是⼀个成熟、易
⽤的图数据库，类似于 MySQL。

\#\# Page 15

图中所列出的开源版 TuGraph ⼏个特性包括：
• 单机版图数据库能够处理数据量⼏个 TB 的数据，前提是磁盘⾜够⼤。
• 成本很低，因为是单机版，部署和运维都很容易。
• 性能很好，我们对其进⾏了⼤量优化。TuGraph 的 LDBC\-SNB 测试⽬前是
世界第⼀，⼤家可以在 GitHub 上获取测试 SNB 的条款并进⾏测试。
• 单机版图数据库是⼀个⾮常易⽤的完整系统，我们提供了导⼊导出⼯具和查
询语⾔。此外，还提供了底层 API，⽤户可以使⽤它来编写复杂的程序。
我们的开源版本的⽬标主要有三点：
⾸先，我们希望提供⼀个免费的图数据库产品，能够让更多的⼈使⽤图数据库，尝
试⽤它来解决问题。
其次，我们希望促进图数据库标准的成形。⽬前图数据库的差异太⼤，每个数据库
都有所不同，我们希望通过提供⼀个参考答案来帮助⼤家达成趋同。这样⼤家就可
以根据我们提供的设计来判断哪些特征合理，如果觉得合理就可以遵循这个设计，
慢慢地⼤家就会逐渐靠近。假如所有产品在主要特征上保持⼀致，这样所有⼈的学
习成本就会降低。
最后，基础研究性问题可以不断优化发展，包括存储⽅⾯的问题，例如哈希可能是
理论上最优的，但是是否还有其他需要调整的东⻄？⽬前没有⼀个很好的研究性平
台让⼤家去进⾏这些尝试和研究，我们希望提供的开源 TuGraph\-DB 能成为这些研
究⼈员的对⽐基线，促进研究的发展。
TuGraph 企业版特⾊
除了开源版本，我们也继续提供商业版本。这个版本包含⼀个分布式图数据库，以
及离线计算引擎和流式图计算功能。此外，我们还提供了 TuGraph Platform ⼀站式
图平台，包括运维、可视化等功能。在这个平台上，⽤户可以在图数据库中执⾏流
式计算，并在线写回数据库。这种⽅式通常⽤于实时查询结果，因为流式计算的时
间可能⽐较⻓，但⽤户可以⽴即查询到较早的结果。这对于在线业务来说⾮常重
要。
商业化产品还提供私有化部署，也可以通过⼀体机的⽅式部署硬件，并将很快推出
云上部署⽅案，这样⼤家就可以在云上体验我们的产品。
总结
蚂蚁在图计算⽅⾯投⼊了⼤量资源，并在众多业务场景中磨练出了⼀整套在线查
询、流式计算、离线分析以及图学习的体系。⽬前，我们已经在 GitHub 上开源了单
机版（https://github.com/TuGraph\-family），同时也提供企业版来满⾜不同⽤户
需求。

\#\# Page 16

陈⽂光：AI时代需要怎样的数据处理技术？
⼤家好，我是清华⼤学/蚂蚁技术研究院陈⽂光，今天为⼤家带来《AI 时代的数据
处理技术》主题分享。
我们身处⼀个以信息技术为核⼼驱动⼒的⼤数据时代。从下⾯这张图，我们可以看
出，数据量和数据⽣成的速度在⻜速增⻓。与此同时，新的产⽣数据的形式在产
⽣，数据模态也在不断增⻓，不仅包括⾃然语⾔，还有声⾳、图像、视频等等多
种形式。最近⾮常流⾏的多模态⼤模型包括具身智能、触觉等新的数据形态。
丰富的数据形态要求我们要对数据做有效处理。模仿“⻢斯洛需求层次理论”，数据
处理也有⼀个层次，从最底下的收集数据、存储数据到做⼀般的数据查询处理，更
上⾯的层次是现在越来越接近于⽤ AI ⽅式处理数据，甚⾄最后还能⽣成很多内容。
1\.AI时代数据处理新需求
这样的⼤模型崛起的时代也引发了对数据处理的新需求。最近，Meta 出了⼀个新
模型 LLaMA\-3，效果⾮常好，它实现了在⼗⼏万亿的 Token 上⾯做的训练，⽽
我们之前很多模型可能只是在 4T 的或者⼏个 T 的 Token上⾯做训练。
那么，如何获得增加的这部分 Token？实际上，这需要从很多⽹上低质量的数据中
做⼤量的数据处理，清洗出来可⽤的⾼质量数据，如果想让⼤模型的能⼒进⼀步
增⻓，实际上需要数据处理做很多的⼯作。
另⼀⽅⾯，⼤模型直接应⽤在⽣产服务场景下，本身还存在很多缺陷，⽐如幻觉问
题、上下⽂⻓度的问题。⽬前的多数超⻓上下⽂⼤模型并不能完整记录真正领域
的知识。为了满⾜需求，向量数据库和⼤语⾔模型结合起来，提供⾼质量的服
务。
从数据服务的⻆度来讲，向量数据库是⼀种使⽤嵌⼊的⽅式表达知识，再⽤另外索
引的⽅式快速找到相应知识的⽅式，它和⼤模型配合才能获得很好的效果。所以⼤
模型的发展和崛起，对数据库领域也提出了很多新需求。
2\.ai时代数据库发展趋势
在这样的趋势下，我今天想分享三个观点，也是未来的数据库⾯临的三个⽐较重要
的发展趋势：
（⼀）在线离线⼀体化
这张图是企业常⻅的在线、离线两个链路。
◦ 上⾯是在线链路，⼀个数据请求会先经过预处理，再通过训练好的模型做推
理，⽐如⻛控、分类等等，再把结果反馈到 KV ⾥，直接服务⽤户的请求。
◦ 下⾯是离线链路，收到数据请求后，我们要想办法处理，去更新模型。经过
⼀段时间后再把模型更新到在线链路上。
在线、离线两个链路分开，在⽣产中会遇到⼀些⽐较严重的问题，主要就是在线、
离线不⼀致。
⽐如在离线链路上做了各种仿真模拟，但是当把策略、模型上传到在线链路时，会

\#\# Page 17

出现与离线链路仿真效果不⼀样的情况。造成这种现象的根本原因，就是我们通
过不同的数据链路把新数据接⼊进来，离线链路处理的数据与在线链路不⼀致。
怎么解决这个问题？最好的解决⽅案，就是只有⼀套数据。如果能够做到⼀个系统
既能够做事务处理，可以⽀持事务在数据上⾯原⼦化地做更新，同时还可以在这
⼀批数据上做后续分析型的业务。也就是说⽤⼀份数据给在线离线链路的⼀致性
打下基础。
这⾥⾯也有⾮常多的技术问题。⼀般来说，事务处理⾏存会⽐较好，分析⼀般是列
存⽐较好，当⼀套系统需要同时⽀持⾏存和列存的时候，需要什么样的存储结
构？另外，事务处理对于优先级、延迟/尾延迟、吞吐率要求⽐较⾼。那么在系统
⾥如何调度不同优先级的请求，这⾥涉及到很多相关技术。
在蚂蚁的图⻛控中，也有另外⼀个场景。刚才我们讲到，可以通过数据库本身的
HTAP 引擎解决在线/离线⼀致性的问题，如果没有这样的混合系统，应该如何实
现两份数据达到在线离线⼀致性？下⾯以图⻛控⽅案中的在线离线⼀体化为例，
给⼤家介绍。
TuGraph DB（分布式图数据库），是⼀个⽀持 事物处理 的图数据库。TuGraph
Dataflow （流图计算系统），可以看作是⼀个⽀持图语义的 Flink。
在我们原来的⽅案中，这两个系统采⽤不同的查询语⾔，⼀个是我们⾃定义的
GQuery 语⾔，另外⼀个是基于 Java 的⽀持 Gremlin 语⾔。这两个系统的数据
通过 TuGraph Dataflow 处理完成后，⼀条线通过 TuGraph DB 去做在线链路，
另外⼀个经过存储去完成后续的离线分析，这时就会出现数据不⼀致的情况。
这个问题如何解决呢？⾸先需要让数据保持⼀致性。数据虽然是两份，但是在
TuGraph DB 和存储之间新增了⼀条数据同步链路，就是通过从 Binlog 中读取数
据，保证两份数据的⼀致性，防⽌出现两边写，⼀边写成功、⼀边写失败，⽽导
致的数据不⼀致。当把在线数据⾥已经处理完成的数据同步⾄离线数据，这时数
据的⼀致性是有保证的。
另外，我们把这两个系统的查询语⾔和语义都统⼀起来，都使⽤国际标准图查询语
⾔ ISO\-GQL，同样⼀套查询语⾔在两个系统上⽤同⼀个语义⽀持，在进⾏后续的
策略分析时，数据和查询语⾔的语义是⼀致的，可以达到更好的⼀致性。
这⾥也存在⾮常复杂的情况。图数据库的基本功能是从⼀个点扩出去很多点，但是
有些点的邻居⾮常多，可能有⼏⼗万、上百万个，所以我们会限制每个点扩展的
点数，⽐如只扩两百个。但同时还需要在两个系统中保证不仅只扩两百个点，这
两百个点都是⼀样的，才能保证数据⼀致性。所以想要在两个系统中要保证数据
⼀致性，需要花费相当⼤的精⼒。
（⼆）向量数据库和关系型数据库⼀体化
向量数据库和⼤语⾔模型的结合有⾮常重要的作⽤，如果⼀个企业要⽤⼤语⾔模型
做服务，既要部署语⾔模型⼜要部署向量数据库，同时企业的很多数据⼜保存在
关系型数据库中。
这样⼀个多系统复杂混合的部署，开发、部署、维护⾮常困难。因为涉及到多个系
统之间的依赖性，软件版本、系统之间的交互也会存在很多的问题。如果能够把
这些功能做到⼀起，就能够实现⼀致性的管理。

\#\# Page 18

在关系型数据库中，可以通过⼀些插件⽀持向量数据库的语义，同时在调⽤查询引
擎的时候，将数据分到不同的链路上执⾏，从⽤户的⻆度就可以实现只部署⼀个
系统，使⽤⼀套语⾔，完成相关⼯作。
蚂蚁集团有⼀套内部的 VSAG 的向量库，实现了主流向量数据库的相关功能，⽽
且在实际⽣产中已经得到应⽤。向量数据库最有名的是 FaceBook 开源的 FAISS
系统。
VSAG 和 FAISS 之间有什么区别？FAISS 功能⾮常强⼤、性能⾮常好，对 GPU 也
做了很多优化，但是相对来说提供了很多底层功能，这就需要通过调整各种参
数、配置，从中得到⼀个对应⽤⽐较合适的配置。
⽽蚂蚁集团的 VSAG 库更多从开发者和产品应⽤性的⻆度出发，默认把很多基础
配置的事情都做好了，⽽且在 CPU 上也实现了很多优化，提供了近似于开箱即
⽤的功能。
在 OceanBase ⾥，以插件的⽅式集成了 VSAG 功能，可以在 OceanBase ⾥使⽤
VSAG 向量化的功能，⽤⼀套系统达到这样的效果。
（三）数据处理与 AI 计算⼀体化
有⼈可能会问，数据处理不就是 SQL 吗？AI 是神经⽹络层⾯的东⻄，AI 与 SQL
为什么会结合到⼀起？我举⼀个例⼦。⼤家知道世界上有很多的⽹⻚，⽹⻚上⾯
有很多内容，内容量⾮常⼤，远超⼏⼗ T、⼏百 T。但是在这些海量内容中，很
多内容质量很低，如何从中提取出⾼质量的内容？FaceBook 提出了⼀套 CCNet
的流程，下图的 CCNet 流程展示了数据处理和 AI 的模型在这⼀过程中的融合试
⽤。
第⼀步， CCNet 对⽹⻚的原始数据进⾏解析，在 HTML 的⽹⻚中抓取内容，这⾥
涉及到解析等⼯作。
第⼆步是删冗，删冗也可以被认为是⼀个 JOIN，因为抓取⽹⻚内容中可能⽤到了
别的⽹⻚内容，语料⾥⾯有冗余不利于最后的训练，即对每段话都做⼀个哈希，
和过去已有的内容对⽐，是相同还是不相同。解析与删冗是⾮常典型的数据处理
过程。
第三步，做语⾔分类，需要经过神经⽹络模型判断⽹⻚的语⾔。
接下来，通过⼀些 AI 模型对数据做分词、质量评估，后⾯的过滤、分桶⼯作，⼜
回到数据处理。
在这个应⽤⾥，数据处理和 AI 计算处于交叠的状态，不是⼀次数据处理之后都交
给AI 完成后续的处理，这是⼀个复杂的来回交互的链路。
那这种情况下，什么样的系统可以⽀撑这样复杂交互的服务？现在的 AI 和⼤数据
⽣态基本是割裂的⽣态：
◦ AI ⽤ Python，主要⽤ GPU ；
◦ ⼤数据基本上是⽤ CPU ，⽤基于 Java 的 Spark 实现。

\#\# Page 19

另⼀⽅⾯，在很多⼩数据的处理上，Python 已经展现出⾮常强⼤的性能，像
Pandas 这样的系统，在单机数据的处理上提供了⾮常⽅便的接⼝。
当 AI 逐渐成为主流计算形态的时候，数据应该如何与 AI 融合？
由于 Spark 是基于 Java 的⽣态，当我们如果把⼤模型处理交给 Spark 去做，它产
出的结果要通过⽂件系统、或者其他传输⽅式交给 AI 的 Python 程序，Python
处理完之后可能还有⼀些后续处理。在刚才的例⼦⾥⾯，数据处理和 AI 计算之间
会有多次的交互，对整个系统的开发、调试、部署、维护带来⾮常⼤的问题。
有⼈尝试把数据处理和 AI 结合起来。2019 年，英特尔出了⼀个系统“BigDL”，在
Spark ⾥⾯把神经⽹络的描述、优化器、训练⽅式把这些东⻄加进去。当时只⽀
持了 CPU，⽽且是基于 Java 的。我们可以认为，这种⽅式是试图把 AI 融⼊到⼤
数据的⽣态⾥⾯。
我们反过来看，如何把⼤数据的⽣态往 AI 的⽅向牵引？这其实是 Spark 的
Python 化。
上图是 2022 年在DataBricks Summit上讲的。这是⼀个分布式的 PySpark，就是
Python 接⼝的 Spark系统。当时 PySpark 的使⽤率已经达到了整个 Spark 使⽤
率的近 50%，很多⼈已经愿意⽤ PySpark 了。但是 PySpark 还存在⼀个问题：
它的性能很差。
Python 是⼀个动态语⾔，在编译时不知道它的类型，动态时才知道，所以它的性
能很差，⽐ Java 的 Spark 还要慢⼀半。所以虽然 PySpark 对编程⾮常友好，很
多⼈也习惯⽤，但是性能不太好。因此我们在处理⼤量数据的时候，希望能够避
免这⼀问题。
所以，我们提出⼀个愿景，融合数据处理和 AI ⽣态。
我认为还是要基于 Python，因为 AI 是主要的计算形式，所以整个数据处理应该围
绕 AI 建设。从编译优化的⻆度来讲，我们希望把 PySpark 做很多的优化。这件
事是可以做的，我们最近也有了⼀些成果。在删冗部分，通过把 PySpark 做相关
优化，基本上性能可以提升⼀倍多，可以达到我们的性能预期。
未来，这个⽣态不只是编程要融合，底层的硬件也要融合，数据和 AI 结合以后，
底层的硬件⽣态也要⽀持 GPU、弹性任务调度，最后可以达到“⼀次编写到处执
⾏”的效果。
3⽉30⽇，TuGraph 社区 Meetup “图数据库智能化建设与探索”在北京顺利举办，
探讨⼤模型时代下的图数据库智能化。请看精彩回顾
👇
01\. 技术分享｜TuGraph计算引擎模型推理系统设计与优化
“虽然传统的基于迭代的算法能够解决我们现实⽣活中的⼤多数问题，但随着业务需
求的不断发展和现实问题的⽇渐复杂化，这些算法往往难以满⾜某些具体的需求。

\#\# Page 20

尤其是当规模和维度⽇益增⻓、数据越发密集时，我们很难利⽤这种传统的⽅法去
提取到更加关键的⼀些信息，或者说是我们从⼈的视⻆上更难理解的⼀些信息。因
此，由于图结构在表达能⼒上的优势，结合机器学习分析技术，图算法近年来引起
了⼴泛关注，并在业界落地和取得了较好的商业价值。”
02\. 技术分享｜TuGraph\-DB兼容Neo4j客户端(cid:49482\) Bolt协议设计与实现
“兼容Neo4j客户端的最⼤优势在于⽣态⽀持。以客户端为例，Neo4j官⽅⾃身⽀持
五种编程语⾔的客户端，社区⼜贡献了两种，共计七种语⾔的客户端得以直接使
⽤。此外，还有⼀系列与上下游⽣态相接的组件，如与Apache Spark或Apache
Kafka的连接，都有现成的代码可供利⽤。在编程框架⽅⾯，特别是Java，例如
OGM（Object\-Graph Mapping，对象图映射）以及⼀些业务开发框架，如
Spring，这些所需的相关代码都已现成，⽆需重新编写。这种做法极⼤地节约了研
发资源，我们可以将这些资源重新投⼊到提升数据库本身能⼒上。”
03\. 技术分享｜知识图谱语义框架SPG及图谱推理
“当前，我们正处于图谱技术发展的第三阶段，这⼀阶段的核⼼是将图谱与⼤型模型
相结合。⽬标转向了知识的标准化、跨领域数据的联通与复⽤。随着这个阶段的深
⼊，简单地在推理过程中融⼊⽂本概念和信息，或者是加⼊交易与社交的实体关
系，已经不能明显提升推理效果了。关键的做法应当是结合实体信息的多元素特征
进⾏深度协作，从⽽更精准地关联相关性，揭示那些稀疏的实体间关系，并实现意
义解释的密集化。”
04\. 技术分享｜CStore Compaction模块的设计与优化
“TuGraph Analytics本质上是⼀款图分析OLAP数据库。CStore作为⼀个单机版存
储引擎，提供了坚实的存储基础。同时，RocksDB也可以作为TuGraph Analytics的
存储基础。我们采⽤LDBC提供的通⽤社交⽹络图数据集进⾏了基准测试，测试涉及
让TuGraph Analytics分别连结RocksDB以及我们⾃有版本的CStore进⾏分析。在
同步与异步compaction（数据压缩整理）两种⽅式下进⾏了读写性能测试：同步⽅
式意味着数据写⼊完成后进⾏compaction，完成之后再进⾏读性能测试；异步⽅式
则是写⼊和compaction同时进⾏，写⼊完成后⽴即测试读性能。在这两种情境下，
使⽤CStore的TuGraph Analytics的读性能超过了使⽤RocksDB的三倍以上。”
05\. 社区规划｜TuGraph 社区技术路线
最后是展望未来环节，TuGraph 开源负责⼈范志东与⼤家分享了⼤模型时代的图计
算要做些什么，包括Q2即将推出的开源数据分析⼯具 OSGraph，Q3即将开源
的 TuGraph 研发平台 TuGraphMaker，结合⼤模型的“与图对话”⼯
具 ChatTuGraph 等项⽬。
06\. 圆桌讨论｜图技术(cid:49477\) 图⽣态(cid:49477\) 图智能在⾃由讨论环节，TuGraph 布道师戚仕鹏
邀请了⼏位 TuGraph 的⽼朋友⼀起聊聊图技术、图⽣态、图智能。包括中国开源先
锋⼈物 、华为产业发展专家、Rust 技术专家⻢全⼀⽼师，北京⼤学前沿交叉学科研
究院数据科学博⼠庞悦，蚂蚁集团知识图谱专家王少⻜，以及TuGraph 开源负责⼈
范志东。各位⽼师就为什么开源、图技术的未来与学术热点、图与AI等话题进⾏了
精彩讨论。2024年，TuGraph 将努⼒更贴近客户，更拥抱开源，更关注⽣态。欢迎
⼤家继续关注！

\#\# Page 21

权威报告：蚂蚁集团TuGraph跻身中国图数据库市场“领导者”象限
蚂蚁技术AntTech TuGraph 2023年07⽉18⽇ 09:25
7⽉15⽇，全球领先的IT市场研究和咨询公司IDC发布了最新的市场研究报告 (cid:49455\)IDC
MarketScape(cid:49482\) 中国图数据库市场⼚商评估(cid:49480\) 2023(cid:49466\)。报告显示，蚂蚁集团⾃研的
企业级图数据管理平台TuGraph跻身"领导者"象限。
（IDC发布的“中国图数据库市场，2023”象限）
IDC在报告中列举了蚂蚁集团TuGraph的五⼤优势。第⼀，TuGraph研发七年多来⽀
持了蚂蚁集团300多种应⽤，在⼤量不同场景中⻓时间使⽤，产品成熟度、丰富度
等⽅⾯具有优势。第⼆，具备业界鲜有的在线、流式、离线"三线⼀致"计算能⼒，
覆盖了毫秒级延迟、分钟级和⼩时级等不同引擎，满⾜不同场景的性能需求。第
三，⽀持每秒千万级查询的超⾼吞吐，毫秒级超低延迟。第四，⽣态⼯具“⼀站式图
研发及可视化平台 TuGraph\-Platform”降低了⽤户使⽤⻔槛。第五，在其他⾮⾦融
场景，如社交推荐、数据⾎缘管理、故障归因分析等场景⼴泛使⽤，应⽤体系成
熟。
本次报告IDC主要评估了中国市场上12家典型的企业级图数据库⼚商，类型覆盖互联
⽹⼚商(cid:49477\) 云服务⼚商(cid:49477\) ⼤数据⼚商等。IDC针对⼊选图数据库⼚商的产品能⼒
(cid:49462\)Capabilities(cid:49473\)和技术战略(cid:49462\)Strategies(cid:49473\)两个维度，考察了⽬前的 产品技术能⼒(cid:49477\)
市场和⽣态以及未来发展战略等，评估了16个细分能⼒指标和4个细分战略指标，包
含72个指标评估项，并配以不同权重。该报告为企业发展图计算和投资选型提供了
有⼒⽀持。
图数据库，即以图（Graph）数据结构来进⾏存储和分析的数据库。与传统数据库
相⽐，图数据库擅⻓关系分析，能更好地管理和组织数据，开发上层智能模型，同
时也能实现海量数据的⾼并发、低延迟分析处理，提⾼数据变现的商业价值。当前
图数据库应⽤主要集中在欺诈检测(cid:49477\) ⼈际关系分析和预测分析等领域。
IDC调研发现，数字经济、产业数字化转型进⼊深化发展阶段，企业对于业务逻辑开
发和关系挖掘需求增强，图数据库市场受⼤型央国企数字化转型政策的推动明显。
95%的企业认为图数据库是重要的数据管理⼯具，超过 65%的⼚商认为在业务上图
数据库优于其他选择。整体来看，图数据库的使⽤仍处于早期阶段，仍然缺乏统⼀
标准范式，技术⽣态环境弱势，低操作⻔槛的图计算平台仍有较⼤缺⼝。
蚂蚁集团从2015年开始布局图技术，与清华⼤学合作研发了⾼性能图数据库
TuGraph，扛住了蚂蚁万亿级业务的⾼性能要求。TuGraph在功能完整性(cid:49477\) 吞吐
率(cid:49477\) 响应时间等技术指标上处于全球领先⽔平，两次打破国际图数据库基准性能测
试世界纪录，成为LDBC\-SNB世界纪录保持者。TuGraph在2021年帮助⽀付宝实现
了资产损失率⼩于亿分之0\.98的⽬标。
⽬前，蚂蚁集团已经开源了TuGraph系统中的单机版图数据TuGraph\-DB和流式图
计算引擎TuGraph\-Analytics。TuGraph\-DB提供了完备的图数据库基础功能和成熟
的产品设计(cid:49480\) 具备完整的事务⽀持和丰富的系统特性，可在单机上部署，使⽤成本
低，⽀持TB级别的数据规模。⽽TuGraph\-Analytics是业界⾸个⼯业级流式图计算
引擎，能够在超⼤规模图上进⾏流式复杂计算。
未来，蚂蚁将持续加强技术开放，为业界带来先进的图计算技术能⼒，与⾏业携⼿
建设图计算技术⽣态。
蚂蚁图数据库再获LDBC权威测试世界第⼀

\#\# Page 22

近⽇，国际权威图数据库测试机构国际关联数据基准委员会（LDBC）公布了⾏业通
⽤的社交⽹络基准测试（LDBC SNB）最新结果。蚂蚁集团图数据库TuGraph打破
官⽅审计测试纪录，再次拿到世界第⼀，这⼀纪录较LDBC早前公布的最⾼纪录吞吐
量提升了52%，也超过了两年前由TuGraph保持的世界纪录1倍以上。
据LDBC官⽅发布的报告，在本次测试中，TuGraph在不同规模的数据集下均表现优
异，在最⼤数据规模300G的数据集（8亿个结点，53亿条边）上，TuGraph的吞吐
率较上⼀次官⽅纪录提升了52%，在系统事务性、可恢复性、正确性、稳定性等⽅
⾯均达到官⽅标准，体现了TuGraph⾼并发低延迟的强⼤性能优势。
为了更加贴近真实场景使测试更加严谨，TuGraph还采⽤了Client/Server部署，将
客户端和服务器分别部署在两台服务器上，在更严苛的条件下（固有⽹络延迟与⽹
络波动）完成了本次测试。
蚂蚁集团也是LDBC最新的⾦融图数据测试基准Finbench的发起⼈和主要建设者。
关于LDBC和SNB测试
LDBC，即“关联数据基准测评委员会”（Linked Data Benchmark Council），是全
球公认的图数据库领域基准指南制定者与测试机构，与TPC并称为国际数据库⾏业
两⼤权威技术组织。
SNB，即社交⽹络基准测试 （Social Network Benchmark），是由LDBC开发的⾯
向图数据库的基准测试（Benchmark）之⼀。SNB测试由于更贴近现实系统，同时
包含了读写任务，简单和复杂查询，规定了系统的响应时间，更能体现系统的综合
性能，是⽬前图数据⾏业最成熟和通⽤的性能测试。
LDBC SNB测试由指定的第三⽅机构进⾏，从数据导⼊到结果验证均由第三⽅在云
平台上执⾏，最终结果由LDBC执⾏委员会进⾏审计并公布，最⼤限度的保证了结果
的可信性。同时，SNB还公布了测试过程所⽤的程序和脚本，以及测试过程中产⽣
的详细结果，进⼀步确保了测试的可复现性。
关于TuGraph
蚂蚁集团图数据库TuGraph是基于图模型的⼀站式数据存储和分析系统，擅⻓处理
⼤规模关联数据的管理和分析，如社交关系、物流服务、设备管⽹、⾦融交易等场
景，数千倍优化分析性能，天然具备数据可视化展示。
TuGraph拥有业界领先的集群规模和性能，是蚂蚁集团⾦融⻛控能⼒的重要基础设
施，显著提升了欺诈洗钱等⾦融⻛险的实时识别能⼒和审理分析效率，提供了稳定
的决策⽀持能⼒，其中，⽀撑⽀付宝的重要⻛险识别能⼒提升了近10倍，⻛险审理
分析效率提升90%。
TuGraph 已被成熟应⽤于安全⻛控、信贷⻛控、知识图谱、数据⾎缘、资⾦分析、
流量归因分析、会员关系等场景，并⾯向⾦融、⼯业、政务服务等⾏业客户。
TuGraph：从清华到蚂蚁
蚂蚁集团图计算TuGraph（原名GeaGraph），是蚂蚁集团与清华⼤学联合研发的⼤
规模图计算系统，构建了⼀套包含图存储、图计算、图学习、图研发平台的完善的
图技术体系，拥有业界领先规模的图集群，是图数据库基准性能测试LDBC\-SNB世
界纪录保持者。
TuGraph是蚂蚁集团⾦融⻛控能⼒的重要基础设施，显著提升了欺诈洗钱等⾦融⻛
险的实时识别能⼒和审理分析效率，并⾯向⾦融、⼯业、政务服务等⾏业客户。
清华时期

\#\# Page 23

早在2010年前后，清华⼤学计算机系⾼性能所就开始图计算相关技术及系统研究。
于2016年成功研发的双⼦星图计算系统⽐业界常⽤的开源图计算引擎GraphX性能提
⾼了约100倍，获得了业界的⼴泛关注。
费⻢时期
为了推动技术的⼴泛应⽤，2016年从事图计算研究的清华师⽣成⽴了费⻢科技有限
公司。费⻢科技在推进双⼦星系统应⽤的同时，进⼀步开发出了具有国际领先性能
的图数据库产品TuGraph，能够⽀持完整的图数据库事务，服务了搜狗搜索、京东
⾦融、以及⼤型国有银⾏、国家级能源企业在内的不同⾏业⽤户，并在2020年通过
了国际图数据库标准组织LDBC的认证测试，认证成绩是第⼆名的7\.6倍。
蚂蚁时期
蚂蚁集团在很多领域具有科技领先能⼒，国内乃⾄全球最⼤的⽤户量和峰值交易量
使得蚂蚁集团对图计算有着丰富的应⽤需求，利⽤图计算技术处理⽀付宝的反欺
诈、反套现等难题，可以⽐传统技术更加适⽤。从2015年起，蚂蚁集团开始⾃主研
发分布式图数据库、流式图计算等图计算技术系统，并在内部应⽤中获得了良好的
效果。
2020年，蚂蚁集团进⼀步整合了⾃有的图计算技术系统GeaBase，以及清华⼤学和
费⻢科技的产品和技术，升级形成了⼀套完整的图计算系统GeaGraph（后统⼀采⽤
TuGraph命名）。这套系统集成了各⽅原有优势，经过多年技术积累和⼤规模实战
打磨，⽆论从功能的完整性，还是吞吐率、响应时间等性能指标，都达到了世界领
先⽔平。
2023开放原⼦全球开源峰会，蚂蚁图计算平台开源业内⾸个⼯业级流图计算引擎
6⽉11⽇，2023开放原⼦全球开源峰会在北京开幕。本次峰会以“开源赋能，普惠未
来”为主题。在⾼峰论坛上(cid:49480\) 蚂蚁技术研究院院⻓(cid:49477\) 图计算负责⼈陈⽂光宣布开源
TuGraph 图计算平台核⼼成员⸺⼯业级流式图计算引擎 TuGraph Analytics(cid:49478\)
去年9⽉，蚂蚁集团开源了 TuGraph 图计算平台中的图数据库 TuGraph DB。这次
开源是 TuGraph 图计算平台的⼜⼀次开源升级，进⼀步加⼤了蚂蚁在图计算基础软
件领域的开放⼒度，也是通过开放协同促进科技创新的实际⾏动。
图（Graph）是⼀种抽象的数据结构，由顶点和边构成。图计算是⼀种以图结构建
模的算法模型，可对⼤规模数据进⾏关系挖掘和复杂计算，实现知识推理和事件溯
源。图计算⽬前已⼴泛应⽤在⾦融、政务、医疗等领域，备受全球研发机构和顶尖
科技公司关注。流式图计算是⼀种将流式计算和图计算结合的交叉创新，融合了流
式计算的⾼度实效性和图计算的灵活性，攻坚难度极⾼。据了解，蚂蚁从2015年开
始探索图计算，布局了图数据库、流式图计算引擎、图学习等相关技术，打造了世
界规模领先的图计算集群，于业界⾸创了⼯业级流式图计算引擎，多次问鼎图数据
库⾏业权威测试 LDBC 世界冠军并保持世界纪录。此次开源的⼯业级流式图计算引
擎是蚂蚁从2017年开始布局打造(cid:49480\) 经过五年多⼯业级应⽤⼤考(cid:49480\) 流式图计算做到了
在千亿数据规模的“图”上秒级延迟计算(cid:49480\) 是蚂蚁⻛控的核⼼基础技术(cid:49480\) 成功解决了
⾦融场景⻛险分析难(cid:49477\) 识别率低(cid:49477\) 时效性差等业界难题(cid:49478\)
图计算是下⼀代⼈⼯智能关键核⼼技术。中国⼯程院院⼠郑纬⺠曾指出(cid:49480\) “⾼性能图
计算是当前全球⼈⼯智能竞争的战略性制⾼点(cid:49480\) 我们要加快攻克技术(cid:49477\) 突破产业瓶
颈(cid:49480\) 防⽌在⾼性能图计算这⼀关键技术领域再被卡脖⼦”(cid:49478\)⽽开源是共享科技成果，
加速先进技术落地的最快路径。陈⽂光强调，开源是蚂蚁的核⼼技术战略，也是⾯
向数字化未来可持续创新的动⼒。此次流式图计算引擎开源，是延续蚂蚁开源核⼼

\#\# Page 24

基础技术的实际动作，希望通过开放成熟的图计算技术，服务更⼴阔的数字化产
业，向世界输出中国科技公司的前沿技术影响⼒。未来，蚂蚁集团也愿意携⼿⾏业
伙伴共同突破技术创新，繁荣开源⽣态。据了解，蚂蚁开源聚焦于数据库、云原
⽣、中间件等基础软件领域，积累了近100个社区头部开源项⽬、近1600个开源仓
库、9⼤核⼼开源项⽬，如“2022世界⼈⼯智能⼤会镇馆之宝”隐语隐私计算技术
栈、分布式数据库 OceanBase、⾏业⾸个通过商⽤密码产品认证的密码学技术“铜
锁”等⾃研核⼼技术。
TuGraph Analytics (别名：GeaFlow) 是蚂蚁集团开源的流图计算引擎，⽀持万亿级
图存储、图表混合处理、实时图计算、交互式图分析等核⼼能⼒，⽬前⼴泛应⽤于
数仓加速、⾦融⻛控、知识图谱以及社交⽹络等场景。
特性
• 分布式实时图计算
• 图表混合处理（SQL\+GQL语⾔）
• 统⼀流批图计算
• 万亿级图原⽣存储
• 交互式图分析
• ⾼可⽤和Exactly Once语义
• ⾼阶API算⼦开发
• UDF/图算法/Connector插件⽀持
• ⼀站式图研发平台
• 云原⽣部署
实时能⼒
相⽐传统的流式计算引擎⽐如Flink、Storm这些以表为模型的实时处理系统⽽⾔，
GeaFlow以图为数据模型，在处理Join关系运算，尤其是复杂多跳的关系运算如3跳
以上的Join、复杂环路查找上具备极⼤的性能优势。
GeaFlow简介
GeaFlow起源
早期的⼤数据分析主要以离线处理为主，以Hadoop为代表的技术栈很好的解决了⼤
规模数据的分析问题。然⽽数据处理的时效性不⾜， 很难满⾜⾼实时需求的场景。
以Storm为代表的流式计算引擎的出现则很好的解决了数据实时处理的问题，提⾼了
数据处理的时效性。 然⽽，Storm本身不提供状态管理的能⼒， 对于聚合等有状态
的计算显得⽆能为⼒。Flink 的出现很好的弥补了这⼀短板，通过引⼊状态管理以及
Checkpoint机制，实现了⾼效的有状态流计算能⼒。
随着数据实时处理场景的丰富，尤其是在实时数仓场景下，实时关系运算(即Stream
Join) 越来越多的成为数据实时化的难点。Flink虽然具备优秀的状态管理能和出⾊的
性能，然⽽在处理Join运算，尤其是3度以上Join时， 性能瓶颈越来越明显。由于需
要在Join两端存放各个输⼊的数据状态，当Join变多时，状态的数据量急剧扩⼤，
性能也变的难以接受。 产⽣这个问题的本质原因是Flink等流计算系统以表作为数据

\#\# Page 25

模型，⽽表模型本身是⼀个⼆维结构，不包含关系的定义和关系的存储， 在处理关
系运算时只能通过Join运算⽅式实现，成本很⾼。
在蚂蚁的⼤数据应⽤场景中，尤其是⾦融⻛控、实时数仓等场景下，存在⼤量Join
运算，如何提⾼Join 的时效性和性能成为我们⾯临的重要挑战，为此我们引⼊了图
模型。图模型是⼀种以点边结构描述实体关系的数据模型，在图模型⾥⾯，点代表
实体， 边代表关系，数据存储层⾯点边存放在⼀起。因此，图模型天然定义了数据
的关系同时存储层⾯物化了点边关系。基于图模型，我们实现了新⼀代实时计算 引
擎GeaFlow，很好的解决了复杂关系运算实时化的问题。⽬前GeaFlow已⼴泛应⽤
于数仓加速、⾦融⻛控、知识图谱以及社交⽹络等场景。
技术架构
GeaFlow整体架构如下所示：
• DSL层：即语⾔层。GeaFlow设计了SQL\+GQL的融合分析语⾔，⽀持对表模
型和图模型统⼀处理。
• Framework层：即框架层。GeaFlow设计了⾯向Graph和Stream的两套API⽀
持流、批、图融合计算，并实现了基于Cycle的统⼀分布式调度模型。
• State层：即存储层。GeaFlow设计了⾯向Graph和KV的两套API⽀持表数据
和图数据的混合存储，整体采⽤了Sharing Nothing的设计，并⽀持将数据持
久化到远程存储。
• Console平台：GeaFlow提供了⼀站式图研发平台，实现了图数据的建模、加
⼯、分析能⼒，并提供了图作业的运维管控⽀持。
• 执⾏环境：GeaFlow可以运⾏在多种异构执⾏环境，如K8S、Ray以及本地模
式。
应⽤场景
实时数仓加速
数仓场景存在⼤量Join运算，在DWD层往往需要将多张表展开成⼀张⼤宽表，以加
速后续查询。当Join的表数量变多时，传统的实时计算引擎很难 保证Join的时效性
和性能，这也成为⽬前实时数仓领域⼀个棘⼿的问题。基于GeaFlow的实时图计算
引擎，可以很好的解决这⽅⾯的问题。 GeaFlow以图作为数据模型，替代DWD层的
宽表，可以实现数据实时构图，同时在查询阶段利⽤图的点边物化特性，可以极⼤
加速关系运算的查询。
实时归因分析
在信息化的⼤背景下，对⽤户⾏为进⾏渠道归因和路径分析是流量分析领域中的核
⼼所在。通过实时计算⽤户的有效⾏为路径，构建出完整的转化路径，能够快速帮
助业务看清楚产品的价值，帮助运营及时调整运营思路。实时归因分析的核⼼要点
是准确性和实效性。准确性要求在成本可控下保证⽤户⾏为路径分析的准确性;实效
性则要求计算的实时性⾜够⾼，才能快速帮助业务决策。 基于GeaFlow流图计算引
擎的能⼒可以很好的满⾜归因分析的准确性和时效性要求。如下图所示：
GeaFlow⾸先通过实时构图将⽤户⾏为⽇志转换成⽤户⾏为拓扑图，以⽤户作为图
中的点，与其相关的每个⾏为构建成从该⽤户指向埋点⻚⾯的⼀条边.然后利⽤流图
计算能⼒分析提前⽤户⾏为⼦图，在⼦图上基于归因路径匹配的规则进⾏匹配计算
得出该成交⾏为相应⽤户的归因路径，并输出到下游系统。
实时反套现

\#\# Page 26

在信贷⻛控的场景下，如何进⾏信⽤卡反套现是⼀个典型的⻛控诉求。基于现有的
套现模式分析，可以看到套现是⼀个环路⼦图，如何快速，⾼效在⼤图中快速判定
套现，将极⼤的增加⻛险的识别效率。以下图为例，通过将实时交易流、转账流等
输⼊数据源转换成实时交易图，然后根据⻛控策略对⽤户交易⾏为做图特征分析，
⽐如环路检查等特征计算，实时提供给决策和监控平台进⾏反套现⾏为判定。通过
GeaFlow实时构图和实时图计算能⼒，可以快速发现套现等异常交易⾏为，极⼤降
低平台⻛险。
深⼊解读TuGraph计算引擎模型推理系统
TuGraph计算引擎模型推理系统将基于迭代计算的图计算框架与模型推理系统相结
合，推理系统可⾃定义推理依赖环境，图迭代计算与推理链路实现隔离。基于共享
内存的跨进程通信⽅式，提⾼了推理数据交换效率，满⾜流图近线推理的时效性。
在蚂蚁集团内部的实际应⽤场景中，⼤幅缩短了模型推理上线的链路与开发时间，
⽤户迭代模型版本更⽅便快捷。
1\. 图算法概述
在计算机科学中，图是⼀种表示实体（节点或顶点）以及实体之间关系（边）的数
据结构。图模型可以天然地描述⽹络结构，能更清晰地表达复杂的数据关系和依
赖，简化关联数据的理解和分析。在不同的场景下，图中点边具备不同的语义信
息。⽐如在资⾦交易场景下，每个⼈可以抽象成⼀个点表示，⼈与⼈之间的转账关
系可以抽象成⼀条边表示。如下图，通过图数据模型反映出各个实体之间的资⾦往
来关系，让数据的关联分析更加直观和⾼效。
资⾦交易图谱示例
在图数据模型上可以执⾏多种图算法，如社区检测，最短路径匹配，环路检测算法
等。通过点边上的迭代计算，探索图模型中各个实体之间的关系。探索过程不依赖
于数据的线性结构，从⽽便于识别隐藏的模式和关联关系。在主流迭代图算法中，
节点通过消息传递的⽅式进⾏通信。每次迭代，节点可以接收来⾃它们邻居的消
息，处理这些消息，然后决定是否发送新的消息给其他节点。迭代算法中，每个节
点有⼀个状态，每次迭代它们都有可能更新这个状态直⾄收敛。例如，在PageRank
算法中，每个节点的状态是其PageRank值，这个值在迭代过程中会随着邻居的值的
更新⽽更新。
图迭代算法解决了经典的图计算问题，但随着业务需求的复杂度提升，基于迭代的
图算法存在着表达能⼒不⾜、⾃适应性能⼒差、异质图处理难度⼤等缺点。近年来
随着深度学习的研究和应⽤的发展，以图神经⽹络（Graph Neural Networks，
GNNs）为代表的⼀类神经⽹络算法，被设计⽤来捕获图中实体（节点）和关系
（边）间的复杂模式。图神经⽹络能够结合节点特征和图的结构来学习节点和边的
表示，相⽐之下，传统的迭代图算法通常不会直接从原始特征中学习，⽽更多地专
注于结构特征。依赖于深度学习的天然优势，GNNs具有更强的表示学习能⼒，可以
⾃动从数据中学习复杂的模式，这使得 GNNs 能够更好地处理多任务学习和迁移学
习等问题。在社交⽹络分析、知识图谱、⽣物分⼦⽹络、推荐系统以及交通⽹络等
领域，得到⼴泛应⽤。
2\. 流图推理简介
TuGraph计算引擎（TuGraph Analytics\[1]）是蚂蚁集团开源的⼤规模分布式实时图
计算引擎（流图引擎），实现了流批⼀体的图计算模型，⽀持了丰富的图计算算
法。TuGraph Analytics的流图计算能⼒，能处理连续输⼊的数据流，并⽀持增量的
计算模式，极⼤得提⾼了数据的计算效率和实时性。TuGraph Analytics解决了业界
⼤规模数据关联分析的实时计算问题，已⼴泛应⽤于数仓加速、⾦融⻛控、知识图

\#\# Page 27

谱以及社交推荐等场景。
随着业务场景中问题复杂度的提升，基于传统的迭代图算法已⽆法满⾜业务的实际
需求。例如在反洗钱场景中，利⽤图神经⽹络算法处理复杂的交易关系，能够捕获
到节点的局部图结构信息。通过聚合邻接节点的特征信息，每个交易节点都可以感
知到周边图⽹络结构的信息。类似的图神经⽹络等AI模型的推理逻辑，是⽆法基于
传统的图迭代计算模式直接⾼效地表达的。
受上述问题启发，我们思考是否可以将TuGraph Analytics的流图计算能⼒与图神经
⽹络等深度学习模型相结合，开发⼀套基于流图计算的模型推理系统。最终期望的
推理系统具备如下能⼒：
• 对于图算法⼯程师，在图迭代计算过程中，能够⽅便地使⽤机器学习模型的
推理能⼒。
• 对于AI算法⼯程师，可以通过TuGraph Analytics分布式流式计算的能⼒实现
实时的模型推理。
众所周知，在深度学习为代表的数据科学领域，Python已经成为数据分析、模型训
练和推理框架的主流开发语⾔，并提供了丰富的开发库和框架⽣态。⽽以Hadoop全
家桶为代表的⼤数据计算引擎领域，基于Java语⾔开发的系统仍占据⼀席之地，当
然TuGraph Analytics也在其中。这种语⾔差异带来的“互操作性”成本，使得相当⼀
部分⼤数据和AI⽣态组件⽆法轻松地融合，这也是TuGraph Analytics⽀持图推理需
要亟待解决的问题。
3\. 系统设计
我们对业内的跨Python \& Java语⾔的⽅案进⾏了充分的调研，通过深⼊对⽐现有的
跨语⾔交互⽅案的性能与效率，最终决定将模型推理任务运⾏于Python原⽣环境中
以发挥出最佳的性能。
1\. OONX
OONX是⼀个开发的⽣态系统，为不同的机器学习框架之间提供⼀个标准的模型表
示格式。它使得开发⼈员能够在不同的框架、⼯具、运⾏时环境之间以⼀种标准⽅
式交换模型，从⽽简化了模型的迁移和部署。
优点
缺点
框架互操作性 转换成本⾼
⽣态系统⽀持 更新滞后
优化推理 版本兼容性
规范化模型格式 性能不⼀致
2\. Jython
以Jython为代表的⽅式，主要思想是在运⾏的宿主虚拟机上，使⽤宿主语⾔重新编
写实现。
优点
缺点
Java集成 版本管理复杂
跨平台 ⽀持库有限
线程 更新滞后
\- ⽀持Python3有限

\#\# Page 28

3\. Py4j
Py4j桥接库为代表的⽅式，以Socket通信模型为基础，实现Python和Java互相访问
对象，⽅法，提供两个程序相互通信的能⼒。
优点
缺点
跨语⾔交互 ⽹络传输
动态代理 部署分发难度⼤
⽀持复杂类型 版本难兼容
API使⽤简易 运⾏时环境依赖复杂
4\. Web服务化
Web服务化是⼀种将机器学习模型部署成⽹络服务，调⽤者通过相应的api获取模型
推理结果。
优点
缺点
扩展性好 性能差
简易且轻量 不适合计算密集型场景
社区⽀持 ⽆状态管理
机器学习类库易集成 并发连接有限
在TuGraph Analytics模型推理系统的架构设计中，核⼼部分是通过C\+\+原⽣语⾔建
⽴起来的⼀座桥梁，实现Python环境和Java虚拟机之间⾼效的数据交互和操作指令
的传递。通过使⽤C\+\+作为媒介语⾔，我们不仅能够利⽤其接近硬件的执⾏效率，
确保数据交互的性能，还能够保证在两个虚拟环境之间数据交换的计算精度和稳定
性。基于共享内存的设计允许Python和JVM进程各⾃独⽴运⾏，既保证了运⾏环境
的安全隔离，⼜能实现数据的⾼效共享。
4\. 技术原理
TuGraph Analytics模型推理系统⼯作流中，Driver端（即控制节点）发挥着⾄关重
要的⻆⾊。该节点运⾏在Java虚拟机进程，是整个推理流程的控制中⼼。Driver端
初始化了⼀个⾮常关键的组件⸺InferenceContext对象，InferenceContext对象被
设计为模型推理流程的核⼼，在JVM环境中创建并负责加载和预处理⽤户提供的模
型⽂件和环境依赖信息。在模型推理任务之前，InferenceContext会详细检查并准
备好模型⽂件，确保能够正确加载到预期的执⾏环境中。InferenceContext也负责
初始化和配置与模型推理相关的虚拟环境，确保正确的Python环境或其他必要的运
⾏时库得以安装和配置。
如图所示，由流式数据源源不断的触发图迭代计算与模型推理⼯作。TuGraph计算
引擎提供了DeltaGraphCompute计算接⼝，⽤户可⾃主定义增量图数据的处理逻
辑，并更新历史的图存储(Graph Store)。通过TuGraph计算引擎模型推理系统，增
量图迭代的中间计算结果，经过推理前置数据处理接⼝，并基于共享内存的跨进程
通信⽅式，将处理后的数据流输⼊到推理进程，完成推理⼯作后的结果参与后续图
迭代计算逻辑。下⽂将详细介绍各个数据接⼝的使⽤。
4\.1 计算推理隔离
在TuGraph Analytics模型推理系统的架构中，集群的⼯作负载分配给多个worker节
点。每个worker节点上运⾏着两个关键进程：负责图数据迭代计算的Java进程，以

\#\# Page 29

及执⾏模型推理的Python进程。为了充分利⽤计算系统的资源，推理进程在没有接
收到推理请求时，会进⼊睡眠状态。这样的设计不仅减少了系统资源的占⽤，⽽且
降低了系统的整体能耗。当推理请求到达时，推理进程会被⽴即唤醒，接收和执⾏
新的推理任务。借助睡眠与唤醒机制以及智能的任务调度策略，可以保证系统能够
以⾼效、稳定、节能的⽅式运⾏，同时满⾜了⼤规模图数据处理和实时推理的需
求。
在每个worker⼯作节点下，按照不同的推理作业级别划分基础的虚拟环境，从⽽保
证⼀个wroker节点也可以⽀持不同推理任务，⽀持标准的requirements.txt管理推
理依赖库。
在图迭代计算进程和推理进程之间通过数据队列实现双边数据的交互，通过在数据
包的头⽂件中插⼊参数个数，⻓度等信息，推理进程在连续若⼲次收到空消息包
后，将⾃动进⼊睡眠状态，释放cpu等资源。图迭代计算进程调⽤推理接⼝时，推理
进程将快速退出睡眠状态，接收输⼊数据并完成推理流程。
4\.2 跨进程数据交换
对于推理数据的交换部分，底层通过C\+\+开发共享内存管理模块，实现两个进程之
间的数据交互。在推理初始化阶段，由InferenceContext对象开辟进程共享内存，
Java进程负责创建并初始化推理（Python）进程，通知推理进程共享内存的地址信
息，并映射到相应的进程。如图，Java进程和推理进程均采⽤C\+\+作为桥梁语⾔，
实现共享内存中数据的流动操作。
在推理系统的性能测试阶段，我们发现推理进程读写进程时，接⼝的调⽤开销不容
忽视。常规的理解认为C\+\+能够优化Python的执⾏效率，但前提是Python的执⾏内
存⾜够复杂，优化执⾏内容的收益远⼤于接⼝的调⽤开销。然⽽，在我们系统设计
中，共享内存的读写接⼝只是操作了内存地址，实现读写指针的移动。因此，接⼝
的调⽤开销也是影响推理性能的关键因素，为此，我们充分调研了业界主流的⽅
案。
解决⽅案
描述
CPython C语⾔实现Python及其解释器（JIT编译器）
ctypes Python标准库
SWIG 开发⼯具，封装native程序接⼝
Pybind11/Boost.python/
轻量级头⽂件库
Nanobind
Cython Python的超集，使⽤C语⾔特性，静态编译
如图所示，我们对⽐了多种Python调⽤C链接库的⽅案，性能是第⼀要素，因此选
择Cython作为推理进程和底层内存交互的⼯具。Cython是⼀个编程语⾔，是
Python语⾔的⼀个超集，它将/C\+\+的静态类型系统融合在了Python中，允许开发者
可以在Python代码中直接使⽤C语⾔的特性，从⽽提⾼程序的执⾏效率。Cython将
Python源代码翻译为C或C\+\+代码，然后将其编译为⼆进制代码，能够显著提⾼数
值计算和循环场景的代码执⾏性能。
4\.3 推理接⼝设计
上⽂介绍了采⽤Cython作为推理进程内存管理的链接⼯具，如下为TuGraph
Analytics模型推理系统的内存管理接⼝设计，提供了初始化，读和写三个接⼝。
1\. 初始化接⼝：负责共享内存地址的映射和读指针的初始化。
2\. 读接⼝：数据bytes的⻓度作为输⼊参数，直接在内存端上移动相应⻓度返回数据

\#\# Page 30

段，并移动到读指针。
3\. 写接⼝：将bytes和bytes⻓度写⼊到共享内存，并移动⾄写指针。
@cython.final
cdef class InferIpc:
cdef MmapIPC \* ipc\_bridge;
cdef uint8\_t\* read\_ptr;
def \_\_cinit\_\_(self, r, w):
self.ipc\_bridge \= new MmapIPC(r, w)
self.read\_ptr \= self.ipc\_bridge.getReadBufferPtr()
cpdef inline bytes readBytes(self, bytesSize):
if bytesSize \=\= 0:
return b""
cdef int readSize
cdef int len\_ \= bytesSize
with nogil:
readSize \= self.ipc\_bridge.readBytes(len\_)
if readSize \=\= 0:
return b""
cdef unsigned char \* binary\_data \= self.read\_ptr
return binary\_data\[:len\_]
cpdef inline bool writeBytes(self, bytesBuf, length):
cdef bool writeFlag
cdef int len\_ \= length
cdef char\* buf\_ \= bytesBuf
with nogil:
writeFlag \= self.ipc\_bridge.writeBytes(buf\_, len\_)
return writeFlag
def \_\_dealloc\_\_(self):
del self.ipc\_bridge
如下为⽤户实现推理的Java接⼝，同其它图迭代计算接⼝⼀样，需要推理的时候直
接调⽤该接⼝，将图迭代的中间结果inputs发送到推理进程并返回模型结果。
public interface GraphInferContext extends Closeable {
OUT infer(Object... inputs);
}
5\. 最佳实践
我们以PageRank任务结合群组打分模型推理流程为例，演示具体的操作流程。
5\.1 数据处理
定义推理数据前后置处理逻辑如下：
import abc
import json
import sys
import os

\#\# Page 31

import torch
class MyInference(TransFormFunction):
def \_\_init\_\_(self):
super().\_\_init\_\_(2\)
def transform\_pre(self, \*args):
return args\[0], args\[1]
def transform\_post(self, \*args):
return args\[0]
5\.2 图迭代推理
定义图迭代计算结合推理逻辑如下：
public static class PRVertexCentricComputeFunction implements
IncVertexCentricComputeFunction {
private IncGraphComputeContext
graphContext;
private IncGraphInferContext inferContext;
@Override
public void init(IncGraphComputeContext graphContext) {
this.graphContext \= graphContext;
this.inferContext \= (IncGraphInferContext) graphContext;
}
@Override
public void evolve(Integer vertexId,
TemporaryGraph temporaryGraph) {
long lastVersionId \= 0L;
IVertex vertex \= temporaryGraph.getVertex();
HistoricalGraph historicalGraph \=
graphContext
.getHistoricalGraph();
if (vertex \=\= null) {
vertex \= historicalGraph.getSnapShot(lastVersionId).vertex().get();
}
if (vertex !\= null) {
List\> newEs \= temporaryGraph.getEdges();
List\> oldEs \=
historicalGraph.getSnapShot(lastVersionId)
.edges().getOutEdges();
if (newEs !\= null) {
for (IEdge edge : newEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);

\#\# Page 32

}
}
if (oldEs !\= null) {
for (IEdge edge : oldEs) {
graphContext.sendMessage(edge.getTargetId(), vertexId);
}
}
}
}
@Override
public void compute(Integer vertexId, Iterator messageIterator) {
int max \= 0;
while (messageIterator.hasNext()) {
int value \= messageIterator.next();
max \= max \> value ? max : value;
}
IVertex vertex \=
graphContext.getTemporaryGraph().getVertex();
IVertex historyVertex \=
graphContext.getHistoricalGraph().getSnapShot(0\).vertex().get();
if (vertex !\= null \&\& max \< vertex.getValue()) {
max \= vertex.getValue();
}
if (historyVertex !\= null \&\& max \< historyVertex.getValue()) {
max \= historyVertex.getValue();
}
graphContext.getTemporaryGraph().updateVertexValue(max);
}
@Override
public void finish(Integer vertexId, MutableGraph mutableGraph) {
IVertex vertex \=
graphContext.getTemporaryGraph().getVertex();
List\> edges \=
graphContext.getTemporaryGraph().getEdges();
if (vertex !\= null) {
mutableGraph.addVertex(0, vertex);
graphContext.collect(vertex);
} else {
LOGGER.info("not found vertex {} in temporaryGraph ", vertexId);
}
if (edges !\= null) {
edges.stream().forEach(edge \-\> {
mutableGraph.addEdge(0, edge);

\#\# Page 33

});
}
List inferInput \= new ArrayList\<\>();
inferInput.add(String.valueOf(vertexId));
inferInput.add("param2");
String infer \= this.inferContext.infer(inferInput.toArray(new Object\[]
{0}));
}
}
5\.3 创建作业
在Console作业管理平台创建⼀个HLA任务，上传图迭代计算jar包，模型⽂件和依
赖管理⽂件。
5\.4 配置参数
配置相关参数，启动运⾏作业即可。
"geaflow.infer.env.enable":"true",
// 初始化虚拟环境等待时间
"geaflow.infer.env.init.timeout.sec":120,
// 是否接收⽇志
"geaflow.infer.env.suppress.log.enable":"true"
6\. 总结
通过将AI模型推理引⼊TuGraph Analytics流图计算系统，让我们能够对图数据进⾏
深度地分析和预测。利⽤最新的机器学习和深度学习技术，TuGraph Analytics图计
算引擎不仅可以对图数据进⾏分类和回归分析，还可以预测未来趋势，从⽽在多个
维度上提供决策⽀持。
希望通过以上的介绍，可以让⼤家对TuGraph Analytics模型推理系统有个⽐较清晰
的了解，⾮常欢迎⼤家加⼊我们社区（https://github.com/TuGraph\-family/
tugraph\-analytics），⼀起构建图数据上的智能化分析能⼒！
Q: TuGraph 的边是否⽀持索引？
A: TuGraph 在引擎层⽀持边索引，可通过存储过程使⽤。Cypher的边索引功能正
在开发⽀持中
Q: TuGraph 单机的QPS是多少？
A: 不同数据规模，不同查询操作的QPS差异较⼤，⽐如LDBC SNB典型图操作超过
1\.2万，参考测试结果：https://www.tugraph.org/blog?id\=0
Q: 可视化⽂件 build 后如何更新到 tugraph 服务？
A: 可视化⽂件打包后，需要进⾏以下操作进⾏替换。
• 登录 tugraph 服务所在的服务或 docker 容器内。
• 通过 lgraph\_server \-\-help 查看服务启动的配置⽂件所在⽬录。通常情况：/
usr/local/etc/lgraph.json
• 查看 /usr/local/etc/lgraph.json⽂件中 web 的配置⽬录。通常情
况：/usr/local/share/lgraph/resource
• 将可视化打包后⽣成的⽂件夹中的内容全部替换到配置⽬录下 /usr/
local/share/lgraph/resource
• 重新启动 tugraph 服务

\#\# Page 34

Q：如何通过 npm run dev，连接已有的 tugraph 服务？
A：启动之前，需要修改⽂件.env.development中
的'VUE\_APP\_REQUESTURL'的配置项。然后在通过npm run dev进⾏启动。
示例：
NODE\_ENV \= development VUE\_APP\_TITLE \= TuGraph(dev)
VUE\_APP\_REQUESTURL \= http://localhost:7070/
Q：client ⽬前有哪些编程语⾔，是否⽀持 node js？
A：⽬前主要⽀持的编程语⾔有 c\+\+,python,java；⽬前不⽀持 node js。使⽤ node
作为主要开发语⾔的⽤户，可以使⽤ tugraph 提供的 restful api 来调⽤。建议使⽤
Cypher 来封装调⽤接⼝。后续版本 restful api 将不再进⾏更新维护，只会保留登
录、登出、刷新 token、cypher 调⽤这⼏个常⻅的 api。
Q：python client 是否⽀持 pip install？client 在哪⾥进⾏引⽤？
A：⽬前 python client 不⽀持 pip 进⾏安装。client 在⽬录https://github.com/
TuGraph\-db/tugraph\-db/tree/master/src/client。
Q: TuGraph 可以对接那些常⽤数据库？
A: TuGraph通过DataX可以实现⼤部分主流数据库的导⼊导出，⽀持的数据库包括
MySQL、Oracle、Hive 等。具体参考https://github.com/TuGraph\-db/DataX
Q：如何加载存储过程或算法包？
A：加载⽅式有两种：
• 第⼀种：通过可视化⻚⾯的插件模块，通过交互操作完成加载。
• 第⼆种：通过 cypher 语句实现存储过程的加载。
CALL
db.plugin.loadPlugin(plugin\_type::STRING,plugin\_name::STRING
,plugin\_content::STRING,code\_type::STRING,plugin\_description
::STRING,read\_only::BOOLEAN) :: (::VOID)
Q：如何调⽤或执⾏存储过程？
A：可以使⽤ cypher 进⾏存储过程的执⾏或调⽤。
CALL
db.plugin.callPlugin(plugin\_type::STRING,plugin\_name::STRING
,param::STRING,timeout::DOUBLE,in\_process::BOOLEAN) ::
(success::BOOLEAN,result::STRING)
Q:开源内置的算法包在哪⾥？
A：代码地址https://github.com/TuGraph\-db/tugraph\-db/tree/master/plugins
Q：如何使⽤ docker 镜像安装？
A：
• 确认本地是否有 docker 环境，可使⽤docker \-v进⾏验证。如果没有请安

\#\# Page 35

装 docker，安装⽅式⻅ docker 官⽹⽂档https://docs.docker.com/
install/ 。
• 下载 docker 镜像，下载⽅式可使⽤docker pull tugraph/tugraph\-
runtime\-centos7，也可以在官⽹下载⻚⾯进⾏下载https://
www.tugraph.org/download\[注：下载的⽂件是\*.tar.gz 的压缩包，不⽤解
压]。
• 如果使⽤ docker pull 下载的镜像则不⽤导⼊镜像。如果使⽤官⽹下载的压缩
包，则要使⽤docker load \-i ./tugraph\_x.y.z.tar\[注：x.y.z 是版
本号的代替符，具体数值根据⾃⼰下载的版本进⾏改写]
• 启动 docker 容器docker run \-d \-p 7070:7070 \-p 9090:9090 \-\-
name tugraph\_demo tugraph/tugraph\-runtime\-centos7
lgraph\_server\[注：具体的镜像名称 tugraph/tugraph\-runtime\-centos7
要以本地实际镜像名称为准，可⽤过 docker images 命令查看]
Q：rpm 包和 deb 包安装后，启动 lgraph\_server 服务。提示缺少'liblgraph.so'报
错？
A：此问题主要是环境变量导致，需要配置环境量。
示例：
export LD\_LIBRARY\_PATH\=/usr/local/lib64
Q：是否⽀持不定⻓边的条件查询？
示例：
MATCH p\=(v)\-\[e:acted\_in\|:rate\*1\..3]\-(v2\) WHERE id(v) IN
\[3937] AND e.stars \= 3 RETURN p LIMIT 100
A：⽬前还不⽀持不定⻓边的过滤查询。⽬前的代替⽅案只能是分开写。上⾯的示
例，就需要从 1 跳到 3 跳都写⼀遍。
Q：如何查询最短路径，shortestPath 函数如何使⽤？
A：使⽤示例如下（示例图谱：MovieDemo）
MATCH (n1 {name:'Corin Redgrave'}),(n2 {name:'Liam
Neeson'})
CALL algo.allShortestPaths(n1,n2\) YIELD
nodeIds,relationshipIds,cost
RETURN nodeIds,relationshipIds,cost
详尽使⽤⽅案请参考官⽹⽂档https://www.tugraph.org/doc?
version\=V3\.3\.0\&id\=10000000000658658。
Q：查询语句 Where 后使⽤ and 进⾏拼接查询速度较慢，语句应如何优化改进？
示例：
MATCH (n1\),(n2\) CALL algo.allShortestPaths(n1,n2\)
YIELD nodeIds,relationshipIds,cost

\#\# Page 36

WHERE id(n1\) IN \[0] AND id(n2\) IN \[3938]
RETURN nodeIds,relationshipIds,cost
A：⽬前 cypher 查询引擎正在优化中。现阶段语句改写可以通过 with 向下传递进
⾏优化。
示例：
MATCH (n1\) where id(n1\) in \[0] with n1
MATCH (n2\) where id(n2\) in \[3938] with n1, n2
CALL algo.allShortestPaths(n1,n2\) YIELD
nodeIds,relationshipIds,cost
RETURN nodeIds,relationshipIds,cost
Q：如何查询任意跳的边？
A：使⽤\*..
示例：
MATCH p\=(a)\-\[\*..]\-(b) WHERE id(a) IN \[3] AND id(b) IN \[19]
RETURN p
Q：报错"User has reached the maximum number of tokens"后，怎么做？
A：这表明当前账号Token数量已达上限10000个。解决⽅法如下，任选其⼀：
1 登出不使⽤的Token。
2 重新启动TuGraph服务，会清空所有Token。
3 Token有效期默认为24⼩时，24⼩时后会⾃动失效并删除。
